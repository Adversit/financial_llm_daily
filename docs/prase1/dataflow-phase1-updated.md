# é‡‘èæƒ…æŠ¥æ—¥æŠ¥ç³»ç»Ÿ - ç¬¬ä¸€é˜¶æ®µæ•°æ®æµç¨‹å›¾ (MVP)

**ç‰ˆæœ¬**: v1.1 (å·²å®ç°)
**æ—¥æœŸ**: 2025-11-06
**æ—¶åŒº**: Asia/Shanghai

---

## ğŸ“… å®Œæ•´æ—¶é—´çº¿

```
05:30 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” è§¦å‘å¯åŠ¨
      â†“
ä¿¡æ¯æºé‡‡é›† (æ¨¡å— A) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” å®é™…è€—æ—¶çº¦ 10-35 åˆ†é’Ÿ
      â†“ ç­‰å¾…é‡‡é›†å®Œæˆ
LLM æŠ½å– (æ¨¡å— B) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” å®é™…è€—æ—¶çº¦ 5-15 åˆ†é’Ÿ
      â†“ ç­‰å¾…æŠ½å–å®Œæˆ
æŠ¥å‘Šç”Ÿæˆ (æ¨¡å— C) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” å®é™…è€—æ—¶çº¦ 2-5 åˆ†é’Ÿ
      â†“ ç­‰å¾…æˆç¨¿å®Œæˆ
é‚®ä»¶æŠ•é€’ (æ¨¡å— D) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” å®é™…è€—æ—¶çº¦ 1-10 åˆ†é’Ÿ
      â†“
å®Œæˆ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” é¢„è®¡ 06:30-07:00 ä¹‹é—´

æ‰§è¡Œæ¨¡å¼ï¼šä¸²è¡Œ (Serial Execution)
- Celery Beat åœ¨ 05:30 è§¦å‘ä»»åŠ¡é“¾ (chain)
- å„æ¨¡å—ä¾æ¬¡ç­‰å¾…ä¸Šä¸€æ¨¡å—å®Œæˆåè‡ªåŠ¨æ‰§è¡Œ
- æ— éœ€æ—¶é—´çª—å£é™åˆ¶ï¼Œä»»åŠ¡å®Œæˆå³å‘é€
- é€‚é… 2C/2G æœåŠ¡å™¨èµ„æºé™åˆ¶ï¼Œç¨³å®šæ€§æœ€é«˜
```

---

## ğŸ”„ é˜¶æ®µ 1: è§¦å‘å¯åŠ¨ (05:30)

```mermaid
graph LR
    A[Celery Beat<br/>å®šæ—¶è§¦å‘] --> B[ä»»åŠ¡åˆ†å‘<br/>Redis é˜Ÿåˆ—]
    B --> C[é‡‡é›†ä»»åŠ¡é˜Ÿåˆ—<br/>crawl_rss<br/>crawl_static]
    C --> D[(sources è¡¨<br/>enabled=true)]
```

**æ‰§è¡Œæµç¨‹**:
1. Celery Beat åœ¨ 05:30 è§¦å‘ `run_daily_report` ä»»åŠ¡ï¼ˆæå‰30åˆ†é’Ÿï¼‰
2. è¯»å– `sources` è¡¨ï¼Œè·å–æ‰€æœ‰ `enabled=true` çš„ä¿¡æ¯æº
3. æ ¹æ®æºç±»å‹åˆ›å»ºå¯¹åº”çš„é‡‡é›†ä»»åŠ¡ï¼ˆRSS/é™æ€ç½‘ç«™ï¼‰
4. ä»»åŠ¡åˆ†å‘åˆ° Redis é˜Ÿåˆ—ï¼Œç­‰å¾… Worker æ‰§è¡Œ

**å…³é”®æ–‡ä»¶**:
- `src/tasks/orchestrator.py::run_daily_report()`
- `src/tasks/celery_app.py` (Celery Beat é…ç½®)

---

## ğŸ”„ é˜¶æ®µ 2: ä¿¡æ¯æºé‡‡é›† (æ¨¡å— A)

### 2.1 RSS é‡‡é›†æµ

```mermaid
graph LR
    A[RSS Feed<br/>æ–°æ™ºå…ƒ/BigQuant<br/>ç­‰â‰¥30æº] --> B[feedparser<br/>è§£æ<br/>å¹¶å‘=10/Dev]
    B --> C[å»HTML<br/>çº¯æ–‡æœ¬]
    C --> D[24hè¿‡æ»¤]
    D --> E{åˆå¹¶è¾“å…¥}
```

**å¤„ç†æ­¥éª¤**:
1. ä½¿ç”¨ `feedparser` è§£æ RSS Feed
2. æå–æ ‡é¢˜ã€é“¾æ¥ã€å‘å¸ƒæ—¶é—´ã€å†…å®¹
3. å»é™¤ HTML æ ‡ç­¾ï¼Œä¿ç•™çº¯æ–‡æœ¬
4. è¿‡æ»¤å‡ºè¿‡å» 24 å°æ—¶çš„æ–‡ç« 

**å…³é”®æ–‡ä»¶**:
- `src/crawlers/rss_crawler.py::RSSCrawler`
- `src/tasks/crawl_tasks.py::crawl_rss_task()`

---

### 2.2 ç½‘ç«™é‡‡é›†æµ

```mermaid
graph LR
    A[ç½‘ç«™æº<br/>OpenAI/Google<br/>Anthropicç­‰] --> B[é™æ€æŠ“å–<br/>requests<br/>å¹¶å‘=2]
    B --> C{å¤±è´¥?}
    C -->|æ˜¯| D[åŠ¨æ€æ¸²æŸ“<br/>Playwright<br/>è¶…æ—¶25s]
    C -->|å¦| E[æ­£æ–‡æŠ½å–<br/>trafilaturaâ†’<br/>readability]
    D --> E
    E --> F[24hè¿‡æ»¤]
    F --> G{åˆå¹¶è¾“å…¥}
```

**å¤„ç†æ­¥éª¤**:
1. ä½¿ç”¨ `requests` è·å–ç½‘é¡µ HTML
2. å¦‚æœé™æ€æŠ“å–å¤±è´¥ï¼Œå›é€€åˆ° Playwright åŠ¨æ€æ¸²æŸ“ï¼ˆæœªå®ç°ï¼‰
3. ä½¿ç”¨ `trafilatura` æˆ– `readability` æå–æ­£æ–‡
4. è¿‡æ»¤å‡ºè¿‡å» 24 å°æ—¶çš„æ–‡ç« 

**å…³é”®æ–‡ä»¶**:
- `src/crawlers/static_crawler.py::StaticCrawler`
- `src/crawlers/text_extractor.py::extract_main_text()`
- `src/tasks/crawl_tasks.py::crawl_static_task()`

---

### 2.3 å»é‡ä¸è½åº“

```mermaid
graph TB
    A{åˆå¹¶è¾“å…¥} --> B[ä¸€çº§å»é‡<br/>canonical_url<br/>æ ‡å‡†åŒ–URL+æ ‡é¢˜+æ—¶é—´]
    B --> C[äºŒçº§å»é‡<br/>SimHash<br/>æ±‰æ˜è·â‰¤3]
    C --> D{ä¿ç•™ç­–ç•¥<br/>æ—¶é—´æ›´æ—©/<br/>æ¥æºæƒå¨}
    D -->|ä¿ç•™| E[(articles è¡¨<br/>source_id, title, url<br/>content_text<br/>simhash, canonical_url<br/>processing_status=raw)]
    D -->|ä¿ç•™| F[(extraction_queue è¡¨<br/>article_id<br/>status=queued<br/>priority=0, attempts=0)]
```

**å»é‡é€»è¾‘**:
1. **ä¸€çº§å»é‡**: ä¼˜å…ˆä½¿ç”¨ `canonical_url`ï¼Œå…œåº•ä½¿ç”¨æ ‡å‡†åŒ– URL + æ ‡é¢˜ + æ—¶é—´è¿‘ä¼¼
2. **äºŒçº§å»é‡**: ä½¿ç”¨ SimHash è®¡ç®—æ–‡æœ¬æŒ‡çº¹ï¼Œæ±‰æ˜è·ç¦» â‰¤3 åˆ¤å®šä¸ºè¿‘é‡å¤
3. **ä¿ç•™ç­–ç•¥**: ä¿ç•™å‘å¸ƒæ—¶é—´æ›´æ—©æˆ–æ¥æºæƒå¨æ€§æ›´é«˜çš„æ–‡ç« 

**å†™å…¥è¡¨**:
- `articles`: å­˜å‚¨æ–‡ç« å†…å®¹ï¼Œ`processing_status='raw'`
- `extraction_queue`: å…¥é˜Ÿå¾…æŠ½å–ï¼Œ`status='queued'`

**å…³é”®æ–‡ä»¶**:
- `src/crawlers/deduplicator.py::Deduplicator`
- `src/tasks/crawl_tasks.py` (è½åº“é€»è¾‘)

---

## ğŸ”„ é˜¶æ®µ 3: LLM æŠ½å– (æ¨¡å— B)

```mermaid
graph TB
    A[(extraction_queue<br/>status=queued<br/>ORDER BY priority)] --> B[(articles<br/>è·å– content_text)]
    B --> C[åˆ†å—å¼•æ“<br/>è¯­ä¹‰åˆ‡åˆ†-æ®µè½+å¥å­<br/>é¢„ç®—70%ä¸Šé™<br/>é‡å 200å­—ç¬¦<br/>æœ€å¤š8æ®µ/æ–‡]
    C --> D{è¿‡é•¿?}
    D -->|>8æ®µ| E[é™çº§ç­–ç•¥<br/>summary_then_extract<br/>æˆ– headN_plus_overall]
    D -->|â‰¤8æ®µ| F[Provider è·¯ç”±<br/>DeepSeek Chat-ä¸»<br/>â†“å¤±è´¥/è¶…æ—¶90s<br/>Qwen Max/Plus-å¤‡]
    E --> F
    F --> G[é€æ®µè°ƒç”¨-æˆ–å¹¶è¡Œ<br/>é‡è¯•2æ¬¡<br/>è¶…æ—¶90s/æ®µ<br/>è¿”å› JSON Schema]
    G --> H[è§£æ JSON<br/>fact / opinion<br/>region / layer<br/>confidence]
    H --> I[åˆå¹¶å»é‡<br/>äº‹å®å½’ä¸€åŒ–<br/>SimHashå»é‡<br/>ç¼–è¾‘è·â‰¤2<br/>ç½®ä¿¡åº¦èšåˆ]
    I --> J{æ–‡ç« çº§çŠ¶æ€<br/>ok / partial / failed}
    J --> K[(extraction_items<br/>article_id, fact, opinion<br/>region, layer<br/>evidence_span<br/>confidence, created_at)]
    J --> L[(æ›´æ–° extraction_queue<br/>status=done/failed<br/>last_error)]
    J --> M[(æ›´æ–° articles<br/>processing_status=<br/>done/failed)]
    J --> N[(provider_usage<br/>provider, model<br/>prompt_tokens<br/>completion_tokens<br/>total_cost)]
```

**æŠ½å–æµç¨‹**:
1. ä» `extraction_queue` è¯»å–å¾…æŠ½å–æ–‡ç« ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
2. è¯»å–æ–‡ç« å†…å®¹ï¼Œè¿›è¡Œè¯­ä¹‰åˆ†å—
3. å¦‚æœåˆ†å—æ•° >8ï¼Œè§¦å‘é™çº§ç­–ç•¥
4. ä½¿ç”¨ Provider è·¯ç”±è°ƒç”¨ LLMï¼ˆDeepSeek ä¸»ï¼ŒQwen å¤‡ï¼‰
5. é€æ®µè°ƒç”¨ LLMï¼Œè§£æè¿”å›çš„ JSON
6. åˆå¹¶å»é‡ï¼Œè§£å†³å†²çª
7. å†™å…¥ `extraction_items` è¡¨
8. æ›´æ–° `extraction_queue` å’Œ `articles` çŠ¶æ€
9. è®°å½• LLM ä½¿ç”¨ç»Ÿè®¡åˆ° `provider_usage`

**JSON Schema**:
```json
{
  "items": [
    {
      "fact": "...",
      "opinion": "...(å¯ä¸ºç©º)",
      "region": "å›½å†…|å›½å¤–|æœªçŸ¥",
      "layer": "æ”¿æ²»|ç»æµ|é‡‘èå¤§æ¨¡å‹æŠ€æœ¯|é‡‘èç§‘æŠ€|æœªçŸ¥",
      "evidence_span": "åŸæ–‡å¥æ®µ",
      "confidence": 0.85
    }
  ]
}
```

**å…³é”®æ–‡ä»¶**:
- `src/nlp/chunking.py::ChunkEngine`
- `src/nlp/provider_router.py::ProviderRouter`
- `src/nlp/extractor.py::Extractor`
- `src/nlp/merger.py::Merger`
- `src/tasks/extract_tasks.py::run_extraction_batch()`

---

## ğŸ”„ é˜¶æ®µ 4: æŠ¥å‘Šç”Ÿæˆ (æ¨¡å— C)

```mermaid
graph TB
    A[(extraction_items<br/>å½“æ—¥æ‰€æœ‰äº‹å®è§‚ç‚¹)] --> B[è¿‡æ»¤ç­›é€‰<br/>confidenceâ‰¥0.6<br/>content_lenâ‰¥120å­—<br/>å»æ°´æ–‡ç« ]
    B --> C[åˆ†åŒºåˆ†ç»„<br/>å›½å†…/å›½å¤– Ã—<br/>-æ”¿æ²»/ç»æµ/<br/>é‡‘èå¤§æ¨¡å‹æŠ€æœ¯/<br/>é‡‘èç§‘æŠ€-]
    C --> D[è¯„åˆ†æ’åº<br/>score=<br/>0.5Ã—å½±å“åŠ›+<br/>0.3Ã—æ–°è¿‘åº¦+<br/>0.2Ã—æƒå¨]
    D --> E[TopN ç­›é€‰<br/>æ¯åŒº Top5]
    E --> F[æ­£æ–‡ HTML<br/>æŠ¬å¤´-é¡¹ç›®å+æ—¥æœŸ<br/>ç›®å½•é”šç‚¹<br/>åˆ†åŒºå¡ç‰‡-TopN-<br/>æ ‡é¢˜é“¾æ¥+æ‘˜è¦+æ ‡ç­¾]
    C --> G[é™„ä»¶ HTML<br/>å…¨é‡äº‹å®è§‚ç‚¹<br/>-ä¸é™TopN-<br/>åŸæ–‡é“¾æ¥å¯ç‚¹<br/>æŒ‰æ¥æº/æ—¶é—´æ’åº]
    F --> H[Jinja2 æ¨¡æ¿æ¸²æŸ“<br/>HTMLç”Ÿæˆ]
    G --> H
    H --> I[ç”Ÿæˆå…ƒæ•°æ®<br/>sections_json<br/>build_meta, build_ms]
    I --> J[(reports è¡¨<br/>report_date<br/>html_body-æ­£æ–‡-<br/>html_attachment-é™„ä»¶-<br/>sections_json<br/>build_meta, build_ms<br/>created_at)]
```

**æŠ¥å‘Šç”Ÿæˆæµç¨‹**:
1. ä» `extraction_items` è¯»å–å½“æ—¥æ‰€æœ‰äº‹å®è§‚ç‚¹
2. è¿‡æ»¤ï¼šconfidence â‰¥ 0.6ï¼Œcontent_len â‰¥ 120å­—
3. åˆ†åŒºåˆ†ç»„ï¼šå›½å†…/å›½å¤– Ã— 4ä¸ªå±‚çº§
4. è¯„åˆ†æ’åºï¼š`score = 0.5Ã—å½±å“åŠ› + 0.3Ã—æ–°è¿‘åº¦ + 0.2Ã—æƒå¨`
5. TopN ç­›é€‰ï¼šæ¯ä¸ªåˆ†åŒºå– Top5
6. ç”Ÿæˆæ­£æ–‡ HTMLï¼ˆTopNï¼‰å’Œé™„ä»¶ HTMLï¼ˆå…¨é‡ï¼‰
7. ä½¿ç”¨ Jinja2 æ¸²æŸ“æ¨¡æ¿
8. ç”Ÿæˆå…ƒæ•°æ®ï¼ˆåˆ†åŒºç»Ÿè®¡ã€æ„å»ºæ—¶é—´ç­‰ï¼‰
9. å†™å…¥ `reports` è¡¨

**æ­£æ–‡ç»“æ„**:
- æŠ¬å¤´ï¼šé¡¹ç›®å + æ—¥æœŸ
- æ€»è§ˆæ‘˜è¦ï¼ˆå¯é€‰ï¼‰
- ç›®å½•é”šç‚¹
- åˆ†åŒºå¡ç‰‡ï¼šæ ‡é¢˜é“¾æ¥ã€1-2å¥å¹²è´§æ‘˜è¦ã€æ ‡ç­¾ï¼ˆregion/layerï¼‰ã€æ¥æºå+å‘å¸ƒæ—¶é—´

**é™„ä»¶ç»“æ„**:
- å…¨é‡äº‹å®ä¸è§‚ç‚¹ï¼ˆä¸é™ TopNï¼‰
- æ¯æ¡å«åŸæ–‡é“¾æ¥
- æŒ‰æ¥æº/æ—¶é—´æ’åº

**å…³é”®æ–‡ä»¶**:
- `src/composer/scorer.py::Scorer`
- `src/composer/builder.py::ReportBuilder`
- `src/composer/templates/email_body.html`
- `src/composer/templates/attachment.html`
- `src/tasks/report_tasks.py::build_report_task()`

---

## ğŸ”„ é˜¶æ®µ 5: é‚®ä»¶æŠ•é€’ (æ¨¡å— D)

```mermaid
graph TB
    A[(reports<br/>å½“æ—¥æŠ¥å‘Š)] --> C[ç»„è£…é‚®ä»¶<br/>ä¸»é¢˜-é‡‘èæƒ…æŠ¥æ—¥æŠ¥-YYYY-MM-DD<br/>æ­£æ–‡-html_body<br/>é™„ä»¶-daily-report-YYYY-MM-DD.html]
    B[(report_recipients<br/>type=recipient<br/>enabled=true)] --> C
    C --> D[åˆ†æ‰¹å¤„ç†<br/>æœ€å¤š50äºº/å°<br/>To + BCC]
    D --> E[èŠ‚æµæ§åˆ¶<br/>1å°/ç§’]
    E --> F[SMTP å‘é€<br/>ç½‘æ˜“ SSL 465<br/>æˆæƒç ç™»å½•<br/>UTF-8ç¼–ç ]
    F --> G{å‘é€çŠ¶æ€?}
    G -->|å¤±è´¥| H[å¤±è´¥é‡è¯•<br/>æœ€å¤š2æ¬¡<br/>é€€é¿å»¶è¿Ÿ]
    H -->|ç¡¬é€€ä¿¡| I[ç¡¬é€€ä¿¡å¤„ç†<br/>-ç”¨æˆ·ä¸å­˜åœ¨-<br/>åŠ å…¥é»‘åå•]
    H --> F
    G -->|æˆåŠŸ/å¤±è´¥| J[(delivery_log<br/>report_id, batch_no<br/>recipients_snapshot<br/>message_id<br/>status-ok/failed/partial-<br/>error_code, error_message<br/>sent_at, duration_ms)]
    J --> K[çª—å£æ£€æŸ¥<br/>06:05-06:20]
    K --> L[âœ“ ç¬¬ä¸€é˜¶æ®µå®Œæˆ]
```

**é‚®ä»¶æŠ•é€’æµç¨‹**:
1. ä» `reports` è¡¨è¯»å–å½“æ—¥æŠ¥å‘Š
2. ä» `report_recipients` è¡¨è¯»å–æ”¶ä»¶äººï¼ˆ`type='recipient'`, `enabled=true`ï¼‰
3. ç»„è£…é‚®ä»¶ï¼šä¸»é¢˜ã€æ­£æ–‡ HTMLã€é™„ä»¶ HTML
4. åˆ†æ‰¹å¤„ç†ï¼šæœ€å¤š 50äºº/å°ï¼Œä½¿ç”¨ To + BCC
5. èŠ‚æµæ§åˆ¶ï¼š1å°/ç§’
6. SMTP å‘é€ï¼šç½‘æ˜“ SSL 465ï¼Œæˆæƒç ç™»å½•ï¼ŒUTF-8 ç¼–ç 
7. æ£€æŸ¥å‘é€çŠ¶æ€
8. å¦‚æœå¤±è´¥ï¼Œé‡è¯•æœ€å¤š 2 æ¬¡ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
9. æ£€æµ‹ç¡¬é€€ä¿¡ï¼ˆç”¨æˆ·ä¸å­˜åœ¨ã€åŸŸåæ— æ•ˆç­‰ï¼‰ï¼ŒåŠ å…¥é»‘åå•
10. è®°å½•æŠ•é€’æ—¥å¿—åˆ° `delivery_log`
11. ~~çª—å£æ£€æŸ¥~~ï¼šä¸²è¡Œæ¨¡å¼ä¸‹æ— éœ€çª—å£æ£€æŸ¥ï¼Œä»»åŠ¡å®Œæˆå³å‘é€

**é‚®ä»¶æ ¼å¼**:
- **ä¸»é¢˜**: `é‡‘èæƒ…æŠ¥æ—¥æŠ¥-2025-11-06`
- **æ­£æ–‡**: HTML (TopN å¡ç‰‡)
- **é™„ä»¶**: `daily-report-2025-11-06.html` (å…¨é‡)

**å…³é”®æ–‡ä»¶**:
- `src/mailer/smtp_client.py::SMTPClient`
- `src/mailer/batcher.py::batch_recipients()`
- `src/mailer/retry_handler.py::send_with_retry()`
- `src/tasks/mail_tasks.py::send_report_task()`

---

## ğŸ“Š æ•°æ®è¡¨å…³ç³»

```mermaid
erDiagram
    sources ||--o{ articles : "1:N"
    articles ||--o{ extraction_queue : "1:1"
    articles ||--o{ extraction_items : "1:N"
    extraction_items }o--|| reports : "N:1"
    reports ||--o{ delivery_log : "1:N"
    report_recipients ||--o{ delivery_log : "N:N"
    extraction_items }o--|| provider_usage : "N:1"
```

---

## âœ… éªŒæ”¶æ ‡å‡†

| é˜¶æ®µ | æ•°æ®éªŒè¯ | é¢„æœŸè€—æ—¶ |
|------|---------|---------|
| **é˜¶æ®µ 1** | Celery Beat è§¦å‘æˆåŠŸ | 05:30 å‡†æ—¶è§¦å‘ |
| **é˜¶æ®µ 2** | articles â‰¥ 10ï¼Œextraction_queue å…¥é˜Ÿ | 10-35 åˆ†é’Ÿï¼ˆå–å†³äºæºæ•°é‡å’Œç½‘ç»œï¼‰ |
| **é˜¶æ®µ 3** | extraction_items â‰¥ 20ï¼Œåˆ†å—/åˆå¹¶æ­£å¸¸ | 5-15 åˆ†é’Ÿï¼ˆå–å†³äºæ–‡ç« æ•°é‡ï¼‰ |
| **é˜¶æ®µ 4** | reports = 1ï¼Œhtml_body å’Œ html_attachment éç©º | 2-5 åˆ†é’Ÿ |
| **é˜¶æ®µ 5** | delivery_log â‰¥ 1ï¼ŒçœŸå®é‚®ä»¶å‘é€æˆåŠŸ | 1-10 åˆ†é’Ÿï¼ˆå–å†³äºæ”¶ä»¶äººæ•°é‡ï¼‰ |
| **ç«¯åˆ°ç«¯** | CLI `run_once --step all` ä¸€æ¬¡è·‘é€š | æ€»è®¡çº¦ 18-65 åˆ†é’Ÿï¼Œé¢„è®¡ 06:30-07:00 å®Œæˆ |

**ä¸²è¡Œæ‰§è¡Œæ¨¡å¼è¯´æ˜**ï¼š
- å„é˜¶æ®µä¾æ¬¡æ‰§è¡Œï¼Œå‰ä¸€é˜¶æ®µå®Œæˆåè‡ªåŠ¨è§¦å‘ä¸‹ä¸€é˜¶æ®µ
- æ— å›ºå®šæ—¶é—´çª—å£é™åˆ¶ï¼Œæ ¹æ®å®é™…æ•°æ®é‡åŠ¨æ€è°ƒæ•´
- ç¨³å®šæ€§æœ€é«˜ï¼Œé€‚é…èµ„æºå—é™ç¯å¢ƒï¼ˆ2C/2Gï¼‰

---

## ğŸš€ æ‰§è¡Œå‘½ä»¤

### æ‰‹åŠ¨è§¦å‘

```bash
# å®Œæ•´æµç¨‹
python -m src.cli.run_once --step all

# å•ç‹¬æ­¥éª¤
python -m src.cli.run_once --step crawl
python -m src.cli.run_once --step extract --date 2025-11-06
python -m src.cli.run_once --step compose --date 2025-11-06
python -m src.cli.run_once --step send --date 2025-11-06
```

### Celery Worker

```bash
# å¯åŠ¨ Worker
celery -A src.tasks.celery_app worker --loglevel=info --concurrency=4

# å¯åŠ¨ Beat (å®šæ—¶ä»»åŠ¡)
celery -A src.tasks.celery_app beat --loglevel=info
```

---

**æ›´æ–°æ—¥æœŸ**: 2025-11-06
**æ–‡æ¡£çŠ¶æ€**: ä¸å®é™…ä»£ç å®Œå…¨åŒæ­¥
