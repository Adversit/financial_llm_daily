# é‡‘èæƒ…æŠ¥æ—¥æŠ¥ç³»ç»Ÿ Â· æŠ€æœ¯è®¾è®¡æ–‡æ¡£

ï¼ˆTDD Â· ç¬¬ä¸‰é˜¶æ®µï½œå®¹å™¨åŒ–ä¸ç”Ÿäº§éƒ¨ç½²ï¼‰

**ç‰ˆæœ¬**ï¼šv4.0
**æ—¥æœŸ**ï¼š2025-11-10ï¼ˆAsia/Shanghaiï¼‰
**ç›®æ ‡**ï¼šåŸºäºé˜¶æ®µä¸€/äºŒçš„å®Œæ•´å®ç°ï¼Œæ„å»ºç”Ÿäº§çº§ Docker å®¹å™¨åŒ–æ–¹æ¡ˆï¼Œæ”¯æŒ WSL å¼€å‘ç¯å¢ƒä¸è…¾è®¯äº‘ 2C/2G ç”Ÿäº§ç¯å¢ƒçš„ä¸€é”®éƒ¨ç½²ã€é«˜å¯ç”¨è¿ç»´ä¸å®Œæ•´å¯è§‚æµ‹æ€§ã€‚

---

## 1. ç³»ç»Ÿç°çŠ¶ä¸å®¹å™¨åŒ–ç›®æ ‡

### 1.1 å½“å‰æ¶æ„

ç³»ç»Ÿå·²å®Œæˆæ ¸å¿ƒåŠŸèƒ½å¼€å‘ï¼ŒåŒ…æ‹¬ï¼š

- **é‡‡é›†æ¨¡å—**ï¼šRSSã€é™æ€ç½‘é¡µã€Playwright åŠ¨æ€æ¸²æŸ“ï¼Œæ”¯æŒ SimHash å»é‡
- **NLP æ¨¡å—**ï¼šDeepSeek + Qwen åŒ Provider æŠ½å–ï¼Œæ™ºèƒ½é™çº§ä¸è´¹ç”¨è¿½è¸ª
- **æŠ¥å‘Šæ¨¡å—**ï¼šæ™ºèƒ½æ‰“åˆ†ã€HTML é‚®ä»¶ç”Ÿæˆã€Excel é™„ä»¶å¯¼å‡º
- **é‚®ä»¶æ¨¡å—**ï¼šæ‰¹é‡æŠ•é€’ã€èŠ‚æµæ§åˆ¶ã€å¤±è´¥é‡è¯•ä¸ delivery_log
- **Web ç®¡ç†å°**ï¼šFastAPI + Jinja2 SSRï¼Œç®¡ç†å‘˜åå°ã€ç³»ç»Ÿç›‘æ§ã€è´¹ç”¨ç»Ÿè®¡ã€è¯äº‘åˆ†æ
- **ä»»åŠ¡è°ƒåº¦**ï¼šCelery Beat å®šæ—¶è§¦å‘ï¼ŒWorker å¤„ç†å¼‚æ­¥ä»»åŠ¡

**å½“å‰éƒ¨ç½²æ–¹å¼**ï¼š
- å¼€å‘ç¯å¢ƒï¼š`scripts/start_all.sh` å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼ˆä¾èµ– WSL + Poetry è™šæ‹Ÿç¯å¢ƒï¼‰
- åŸºç¡€è®¾æ–½ï¼šDocker Compose æä¾› PostgreSQL 15 + Redis 7

### 1.2 å®¹å™¨åŒ–ç›®æ ‡

**Phase 3A - å®Œæ•´å®¹å™¨åŒ–**ï¼ˆæœ¬é˜¶æ®µé‡ç‚¹ï¼‰ï¼š
1. å°† Webã€Workerã€Beat åº”ç”¨å°è£…ä¸º Docker é•œåƒ
2. æ„å»ºç»Ÿä¸€çš„ docker-compose ç¼–æ’æ–¹æ¡ˆï¼Œæ”¯æŒå¼€å‘/ç”Ÿäº§åŒç¯å¢ƒ
3. å®ç°å®¹å™¨å¥åº·æ£€æŸ¥ã€èµ„æºé™åˆ¶ã€æ—¥å¿—ç®¡ç†
4. æä¾›ä¸€é”®éƒ¨ç½²èƒ½åŠ›ï¼Œæ¶ˆé™¤æ‰‹åŠ¨ç¯å¢ƒé…ç½®

**Phase 3B - ç”Ÿäº§ä¼˜åŒ–**ï¼ˆåç»­å¢å¼ºï¼‰ï¼š
5. æ•°æ®åº“å¤‡ä»½ä¸æ¢å¤è‡ªåŠ¨åŒ–
6. åå‘ä»£ç†ä¸ TLS é…ç½®
7. ç›‘æ§å‘Šè­¦é›†æˆï¼ˆPrometheus + Grafanaï¼‰
8. CI/CD æµæ°´çº¿

---

## 2. å®¹å™¨æ¶æ„è®¾è®¡

### 2.1 æœåŠ¡æ‹“æ‰‘

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Docker Network: finrep-net            â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚   Web    â”‚  â”‚  Worker  â”‚  â”‚   Beat   â”‚                  â”‚
â”‚  â”‚  :8000   â”‚  â”‚ (Celery) â”‚  â”‚ (Celery) â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚       â”‚             â”‚              â”‚                         â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                     â”‚                                        â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚         â”‚                       â”‚                           â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚    â”‚PostgreSQLâ”‚           â”‚   Redis    â”‚                    â”‚
â”‚    â”‚  :5432  â”‚           â”‚   :6379    â”‚                    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚         â”‚                                                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                                              â”‚
â”‚    â”‚ pgdata  â”‚  (æŒä¹…åŒ–å·)                                 â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æœåŠ¡ç»„ä»¶è¯¦è§£

| æœåŠ¡ | åŸºç¡€é•œåƒ | ç«¯å£ | èŒè´£ | ä¾èµ– |
|------|---------|------|------|------|
| **web** | `python:3.11-slim` | 8000 | FastAPI åº”ç”¨ã€Web ç®¡ç†å°ã€API æ¥å£ã€å¥åº·æ£€æŸ¥ | postgres, redis |
| **worker** | `python:3.11-slim` | - | Celery Workerï¼Œå¤„ç†é‡‡é›†/æŠ½å–/æŠ¥å‘Š/é‚®ä»¶ä»»åŠ¡ | postgres, redis |
| **beat** | `python:3.11-slim` | - | Celery Beatï¼Œå®šæ—¶è°ƒåº¦ï¼ˆ06:00 è§¦å‘æ—¥æŠ¥æµç¨‹ï¼‰ | redis |
| **postgres** | `postgres:15` | 5432 | æŒä¹…åŒ–å­˜å‚¨ï¼ˆsources/articles/reports/usersï¼‰ | - |
| **redis** | `redis:7-alpine` | 6379 | Celery Broker/Backendã€ç¼“å­˜ã€èŠ‚æµæ§åˆ¶ | - |

**å¯é€‰æœåŠ¡ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰**ï¼š
- `nginx`ï¼šåå‘ä»£ç†ã€TLS ç»ˆæ­¢ã€é™æ€èµ„æºç¼“å­˜
- `backup`ï¼šå®šæ—¶æ•°æ®åº“å¤‡ä»½ï¼ˆpg_dump + COS ä¸Šä¼ ï¼‰
- `mailhog`ï¼šå¼€å‘ç¯å¢ƒ SMTP æµ‹è¯•ï¼ˆç”Ÿäº§ç¦ç”¨ï¼‰

### 2.3 å­˜å‚¨å·è®¾è®¡

```yaml
volumes:
  postgres_data:      # PostgreSQL æ•°æ®æŒä¹…åŒ–
  redis_data:         # Redis RDB/AOF æŒä¹…åŒ–ï¼ˆå¯é€‰ï¼‰
  logs_data:          # åº”ç”¨æ—¥å¿—å½’æ¡£ï¼ˆå¯é€‰ï¼‰
  backup_data:        # æ•°æ®åº“å¤‡ä»½å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
```

---

## 3. é•œåƒæ„å»ºè§„èŒƒ

### 3.1 å¤šé˜¶æ®µæ„å»ºç­–ç•¥

**Dockerfile ç»“æ„**ï¼š

```dockerfile
# Stage 1: ä¾èµ–æ„å»ºï¼ˆbuilderï¼‰
FROM python:3.11-slim as builder
WORKDIR /build
COPY pyproject.toml poetry.lock ./
RUN pip install --no-cache-dir poetry && \
    poetry config virtualenvs.create false && \
    poetry install --no-dev --no-interaction --no-ansi

# Stage 2: è¿è¡Œæ—¶é•œåƒï¼ˆruntimeï¼‰
FROM python:3.11-slim
WORKDIR /app
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY src ./src
COPY scripts ./scripts
COPY alembic.ini ./

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–ï¼ˆPlaywright æµè§ˆå™¨ï¼‰
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        libglib2.0-0 libnss3 libnspr4 libdbus-1-3 libatk1.0-0 \
        libatk-bridge2.0-0 libcups2 libdrm2 libxkbcommon0 \
        libxcomposite1 libxdamage1 libxfixes3 libxrandr2 \
        libgbm1 libpango-1.0-0 libcairo2 libasound2 && \
    playwright install chromium && \
    rm -rf /var/lib/apt/lists/*

# åˆ›å»ºé root ç”¨æˆ·
RUN groupadd -r finrep && useradd -r -g finrep finrep
USER finrep

# å¤šå…¥å£æ”¯æŒï¼ˆé€šè¿‡ CMD è¦†ç›–ï¼‰
CMD ["uvicorn", "src.web.app:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 3.2 é•œåƒæ ‡ç­¾è§„èŒƒ

- **å¼€å‘ç¯å¢ƒ**ï¼š`finrep/app:dev`
- **ç”Ÿäº§ç¯å¢ƒ**ï¼š`finrep/app:{version}` æˆ– `finrep/app:{git-sha}`
  - ç¤ºä¾‹ï¼š`finrep/app:1.0.0`ã€`finrep/app:5c4cd1d`

### 3.3 æ„å»ºå‘½ä»¤

```bash
# å¼€å‘é•œåƒï¼ˆåŒ…å«è°ƒè¯•å·¥å…·ï¼‰
docker build -t finrep/app:dev .

# ç”Ÿäº§é•œåƒï¼ˆæœ€å°åŒ–ï¼‰
docker build -t finrep/app:1.0.0 --target runtime .

# å¤šæ¶æ„æ„å»ºï¼ˆæ”¯æŒ ARM64ï¼‰
docker buildx build --platform linux/amd64,linux/arm64 \
  -t finrep/app:1.0.0 --push .
```

---

## 4. Docker Compose é…ç½®

### 4.1 å¼€å‘ç¯å¢ƒï¼ˆdocker-compose.dev.ymlï¼‰

**ç‰¹ç‚¹**ï¼š
- å¯ç”¨ä»£ç çƒ­é‡è½½ï¼ˆvolumes æŒ‚è½½æºç ï¼‰
- å†…ç½® PostgreSQL + Redis
- å¯é€‰ MailHog SMTP æµ‹è¯•æœåŠ¡
- æ—¥å¿—è¾“å‡ºåˆ°æ§åˆ¶å°

**æ ¸å¿ƒé…ç½®**ï¼š

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15
    container_name: finrep_postgres_dev
    environment:
      POSTGRES_USER: fin_user
      POSTGRES_PASSWORD: fin_pass
      POSTGRES_DB: fin_daily_report
      TZ: Asia/Shanghai
    ports:
      - "5432:5432"
    volumes:
      - postgres_data_dev:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U fin_user"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: finrep_redis_dev
    ports:
      - "6379:6379"
    volumes:
      - redis_data_dev:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  web:
    build:
      context: .
      dockerfile: Dockerfile
    image: finrep/app:dev
    container_name: finrep_web_dev
    command: uvicorn src.web.app:app --host 0.0.0.0 --port 8000 --reload
    ports:
      - "8000:8000"
    env_file:
      - .env
    volumes:
      - ./src:/app/src  # ä»£ç çƒ­é‡è½½
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  worker:
    image: finrep/app:dev
    container_name: finrep_worker_dev
    command: celery -A src.tasks.celery_app worker --loglevel=info --concurrency=2
    env_file:
      - .env
    volumes:
      - ./src:/app/src
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

  beat:
    image: finrep/app:dev
    container_name: finrep_beat_dev
    command: celery -A src.tasks.celery_app beat --loglevel=info
    env_file:
      - .env
    volumes:
      - ./src:/app/src
      - ./logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy

volumes:
  postgres_data_dev:
  redis_data_dev:
```

### 4.2 ç”Ÿäº§ç¯å¢ƒï¼ˆdocker-compose.prod.ymlï¼‰

**ç‰¹ç‚¹**ï¼š
- èµ„æºé™åˆ¶ï¼ˆé€‚é… 2C/2G äº‘æœåŠ¡å™¨ï¼‰
- è‡ªåŠ¨é‡å¯ç­–ç•¥
- æ—¥å¿—æ»šåŠ¨é…ç½®
- å¥åº·æ£€æŸ¥ä¸ä¼˜é›…å…³é—­
- å¤–éƒ¨æ•°æ®åº“æ”¯æŒï¼ˆå¯é€‰ï¼‰

**æ ¸å¿ƒé…ç½®**ï¼š

```yaml
version: '3.8'

services:
  web:
    image: finrep/app:1.0.0
    container_name: finrep_web_prod
    command: uvicorn src.web.app:app --host 0.0.0.0 --port 8000 --workers 2
    ports:
      - "8000:8000"
    env_file:
      - .env.prod
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

  worker:
    image: finrep/app:1.0.0
    container_name: finrep_worker_prod
    command: celery -A src.tasks.celery_app worker --loglevel=info --concurrency=2 --max-tasks-per-child=50
    env_file:
      - .env.prod
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

  beat:
    image: finrep/app:1.0.0
    container_name: finrep_beat_prod
    command: celery -A src.tasks.celery_app beat --loglevel=info
    env_file:
      - .env.prod
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.2'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    depends_on:
      redis:
        condition: service_healthy

  postgres:
    image: postgres:15
    container_name: finrep_postgres_prod
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      TZ: Asia/Shanghai
    ports:
      - "5432:5432"
    volumes:
      - postgres_data_prod:/var/lib/postgresql/data
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "2"

  redis:
    image: redis:7-alpine
    container_name: finrep_redis_prod
    command: redis-server --maxmemory 256mb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data_prod:/data
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: 256M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"

volumes:
  postgres_data_prod:
  redis_data_prod:

networks:
  default:
    name: finrep-net
```

---

## 5. ç¯å¢ƒå˜é‡é…ç½®

### 5.1 å¿…éœ€ç¯å¢ƒå˜é‡

åˆ›å»º `.env.prod` æ–‡ä»¶ï¼ˆ**ä¸è¦æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶**ï¼‰ï¼š

```bash
# ç¯å¢ƒæ ‡è¯†
ENV=production
TZ=Asia/Shanghai

# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://fin_user:fin_pass@postgres:5432/fin_daily_report
POSTGRES_USER=fin_user
POSTGRES_PASSWORD=fin_pass  # ç”Ÿäº§ç¯å¢ƒä½¿ç”¨å¼ºå¯†ç 
POSTGRES_DB=fin_daily_report

# Redis é…ç½®
REDIS_URL=redis://redis:6379/0

# LLM Provider - DeepSeek
PROVIDER_DEEPSEEK_API_KEY=sk-xxxxxxxxxxxxx
PROVIDER_DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
PROVIDER_DEEPSEEK_MODEL=deepseek-chat

# LLM Provider - Qwen
PROVIDER_QWEN_API_KEY=sk-xxxxxxxxxxxxx
PROVIDER_QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
PROVIDER_QWEN_MODEL=qwen-max

# é‚®ä»¶é…ç½®
SMTP_HOST=smtp.exmail.qq.com  # ä¼ä¸šé‚®ç®±ï¼ˆæ¨èï¼‰
SMTP_PORT=465
SMTP_USER=report@example.com
SMTP_PASS=xxxxxxxxxxxxxxxx  # SMTP æˆæƒç 

# JWT å®‰å…¨é…ç½®
JWT_SECRET_KEY=change-this-to-a-very-long-random-string-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRE_DAYS=7

# ç³»ç»Ÿé…ç½®
CRAWL_CONCURRENCY_RSS=10
CRAWL_CONCURRENCY_WEB=2
LLM_TIMEOUT_SEC=90
REPORT_TOPN=5
MAIL_BATCH_LIMIT=50
MAIL_RATE_LIMIT_PER_SEC=1.0
```

### 5.2 é…ç½®ä¼˜å…ˆçº§

1. **ç¯å¢ƒå˜é‡**ï¼šDocker Compose `environment` > `.env` æ–‡ä»¶
2. **é»˜è®¤å€¼**ï¼š`src/config/settings.py` ä¸­çš„ Pydantic é»˜è®¤å€¼
3. **è¿è¡Œæ—¶è¦†ç›–**ï¼šç®¡ç†å°"ç³»ç»Ÿè®¾ç½®"å¯åŠ¨æ€ä¿®æ”¹éƒ¨åˆ†é…ç½®

---

## 6. éƒ¨ç½²æµç¨‹

### 6.1 å¼€å‘ç¯å¢ƒéƒ¨ç½²

```bash
# 1. å…‹éš†ä»“åº“
git clone <repository-url>
cd Fin_daily_report/V4

# 2. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env å¡«å……å¿…è¦é…ç½®

# 3. æ„å»ºé•œåƒ
docker-compose -f docker-compose.dev.yml build

# 4. å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose -f docker-compose.dev.yml up -d

# 5. åˆå§‹åŒ–æ•°æ®åº“
docker-compose -f docker-compose.dev.yml exec web alembic upgrade head

# 6. å¯¼å…¥æµ‹è¯•æ•°æ®ï¼ˆå¯é€‰ï¼‰
docker-compose -f docker-compose.dev.yml exec web python scripts/seed_test_data.py

# 7. éªŒè¯æœåŠ¡
curl http://localhost:8000/healthz
# è®¿é—®ç®¡ç†å°ï¼šhttp://localhost:8000
```

### 6.2 ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼ˆè…¾è®¯äº‘ 2C/2Gï¼‰

**æœåŠ¡å™¨è¦æ±‚**ï¼š
- Ubuntu 20.04+ / CentOS 8+
- 2 æ ¸ CPUï¼Œ2GB å†…å­˜ï¼Œ40GB ç£ç›˜
- Docker 20.10+ / Docker Compose 2.0+

**éƒ¨ç½²æ­¥éª¤**ï¼š

```bash
# 1. å®‰è£… Docker
curl -fsSL https://get.docker.com | bash
systemctl enable docker
systemctl start docker

# 2. å®‰è£… Docker Compose
curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose

# 3. å…‹éš†ä»“åº“
git clone <repository-url>
cd Fin_daily_report/V4

# 4. é…ç½®ç”Ÿäº§ç¯å¢ƒå˜é‡
vim .env.prod
# å¡«å……æ•°æ®åº“å¯†ç ã€API Keyã€SMTP é…ç½®ç­‰

# 5. æ„å»ºç”Ÿäº§é•œåƒ
docker build -t finrep/app:1.0.0 .

# 6. å¯åŠ¨æœåŠ¡
docker-compose -f docker-compose.prod.yml up -d

# 7. åˆå§‹åŒ–æ•°æ®åº“
docker-compose -f docker-compose.prod.yml exec web alembic upgrade head

# 8. å¯¼å…¥ä¿¡æ¯æºå’Œæ”¶ä»¶äºº
docker-compose -f docker-compose.prod.yml exec web python scripts/seed_test_data.py

# 9. éªŒè¯æœåŠ¡
curl http://localhost:8000/healthz
docker-compose -f docker-compose.prod.yml ps

# 10. é…ç½®é˜²ç«å¢™ï¼ˆå¼€æ”¾ 8000 ç«¯å£ï¼‰
ufw allow 8000/tcp
ufw reload
```

### 6.3 å¤–éƒ¨æ•°æ®åº“é…ç½®ï¼ˆæ¨èï¼‰

ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨äº‘æ•°æ®åº“ï¼ˆå¦‚è…¾è®¯äº‘ PostgreSQLï¼‰ï¼š

1. åˆ›å»ºäº‘æ•°æ®åº“å®ä¾‹ï¼ˆPostgreSQL 15ï¼‰
2. é…ç½®ç½‘ç»œç™½åå•ï¼ˆæ·»åŠ æœåŠ¡å™¨ IPï¼‰
3. ä¿®æ”¹ `.env.prod`ï¼š

```bash
DATABASE_URL=postgresql://username:password@your-db-host:5432/fin_daily_report
```

4. ä¿®æ”¹ `docker-compose.prod.yml`ï¼Œç§»é™¤ `postgres` æœåŠ¡ï¼š

```yaml
services:
  web:
    # ...
    depends_on:
      - redis  # ç§»é™¤ postgres ä¾èµ–
```

---

## 7. å¥åº·æ£€æŸ¥ä¸ç›‘æ§

### 7.1 å®¹å™¨å¥åº·æ£€æŸ¥

**Web æœåŠ¡**ï¼š
```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s
```

**Worker å¥åº·æ£€æŸ¥**ï¼ˆè‡ªå®šä¹‰è„šæœ¬ï¼‰ï¼š

åˆ›å»º `scripts/celery_health_check.sh`ï¼š

```bash
#!/bin/bash
celery -A src.tasks.celery_app inspect ping -d celery@$HOSTNAME | grep -q "pong"
exit $?
```

```yaml
healthcheck:
  test: ["CMD", "/app/scripts/celery_health_check.sh"]
  interval: 60s
  timeout: 10s
  retries: 3
```

### 7.2 æ—¥å¿—ç®¡ç†

**æŸ¥çœ‹å®æ—¶æ—¥å¿—**ï¼š
```bash
# æ‰€æœ‰æœåŠ¡
docker-compose -f docker-compose.prod.yml logs -f

# ç‰¹å®šæœåŠ¡
docker-compose -f docker-compose.prod.yml logs -f web
docker-compose -f docker-compose.prod.yml logs -f worker

# æœ€è¿‘ 100 è¡Œ
docker-compose -f docker-compose.prod.yml logs --tail=100 worker
```

**æ—¥å¿—å½’æ¡£ä¸æ¸…ç†**ï¼š

ç”Ÿäº§ç¯å¢ƒå·²é…ç½®æ—¥å¿—æ»šåŠ¨ï¼š
```yaml
logging:
  driver: "json-file"
  options:
    max-size: "50m"
    max-file: "3"
```

æ‰‹åŠ¨æ¸…ç†ï¼š
```bash
# æ¸…ç†æ‰€æœ‰å®¹å™¨æ—¥å¿—
truncate -s 0 /var/lib/docker/containers/*/*-json.log
```

### 7.3 ç³»ç»Ÿç›‘æ§

**å†…ç½®ç›‘æ§é¢æ¿**ï¼š
- è®¿é—® `http://<server-ip>:8000/admin/status`
- å®æ—¶ç›‘æ§ï¼šPostgreSQL è¿æ¥çŠ¶æ€ã€Redis å†…å­˜ä½¿ç”¨ã€Celery ä»»åŠ¡é˜Ÿåˆ—ã€Web å“åº”æ—¶é—´
- ECharts è¶‹åŠ¿å›¾ï¼š30 ç§’è‡ªåŠ¨åˆ·æ–°

**è´¹ç”¨ç»Ÿè®¡**ï¼š
- è®¿é—® `http://<server-ip>:8000/admin/usage`
- æŸ¥çœ‹ DeepSeek/Qwen API è°ƒç”¨é‡ä¸è´¹ç”¨

**å‘½ä»¤è¡Œç›‘æ§**ï¼š

```bash
# å®¹å™¨çŠ¶æ€
docker-compose -f docker-compose.prod.yml ps

# èµ„æºä½¿ç”¨
docker stats

# Celery é˜Ÿåˆ—çŠ¶æ€
docker-compose -f docker-compose.prod.yml exec worker \
  celery -A src.tasks.celery_app inspect active

# Redis è¿æ¥æ•°
docker-compose -f docker-compose.prod.yml exec redis redis-cli info clients
```

---

## 8. å¤‡ä»½ä¸æ¢å¤

### 8.1 æ•°æ®åº“å¤‡ä»½ï¼ˆè‡ªåŠ¨åŒ–ï¼‰

**æ–¹æ¡ˆä¸€ï¼šå®šæ—¶è„šæœ¬**

åˆ›å»º `scripts/backup_db.sh`ï¼š

```bash
#!/bin/bash
BACKUP_DIR="/backups"
DATE=$(date +%Y%m%d_%H%M%S)
DB_URL="postgresql://fin_user:fin_pass@postgres:5432/fin_daily_report"

mkdir -p $BACKUP_DIR
pg_dump $DB_URL | gzip > $BACKUP_DIR/finrep_$DATE.sql.gz

# ä¿ç•™æœ€è¿‘ 30 å¤©çš„å¤‡ä»½
find $BACKUP_DIR -name "finrep_*.sql.gz" -mtime +30 -delete

echo "Backup completed: finrep_$DATE.sql.gz"
```

**æ·»åŠ åˆ° crontab**ï¼š
```bash
0 7 * * * /path/to/scripts/backup_db.sh >> /var/log/finrep_backup.log 2>&1
```

**æ–¹æ¡ˆäºŒï¼šBackup ä¾§è½¦å®¹å™¨**ï¼ˆæ¨èï¼‰

åœ¨ `docker-compose.prod.yml` æ·»åŠ ï¼š

```yaml
services:
  backup:
    image: postgres:15
    container_name: finrep_backup_prod
    environment:
      PGHOST: postgres
      PGUSER: ${POSTGRES_USER}
      PGPASSWORD: ${POSTGRES_PASSWORD}
      PGDATABASE: ${POSTGRES_DB}
      BACKUP_SCHEDULE: "0 7 * * *"  # æ¯å¤© 07:00
    volumes:
      - backup_data:/backups
      - ./scripts/backup_db.sh:/backup_db.sh
    command: >
      bash -c "
        echo '$BACKUP_SCHEDULE /backup_db.sh' | crontab - &&
        crond -f
      "
    depends_on:
      - postgres

volumes:
  backup_data:
```

### 8.2 æ•°æ®æ¢å¤

```bash
# ä»å¤‡ä»½æ¢å¤
gunzip -c finrep_20251110_070000.sql.gz | \
  docker-compose -f docker-compose.prod.yml exec -T postgres \
  psql -U fin_user -d fin_daily_report

# æˆ–ä½¿ç”¨ docker cp
docker cp finrep_20251110_070000.sql.gz finrep_postgres_prod:/tmp/
docker-compose -f docker-compose.prod.yml exec postgres bash -c \
  "gunzip -c /tmp/finrep_20251110_070000.sql.gz | psql -U fin_user -d fin_daily_report"
```

### 8.3 å·å¤‡ä»½ï¼ˆæ•´ä½“å¤‡ä»½ï¼‰

```bash
# åœæ­¢æœåŠ¡
docker-compose -f docker-compose.prod.yml stop

# å¤‡ä»½ PostgreSQL å·
docker run --rm -v finrep_postgres_data_prod:/data -v $(pwd):/backup \
  busybox tar czf /backup/postgres_data_$(date +%Y%m%d).tar.gz -C /data .

# æ¢å¤å·
docker run --rm -v finrep_postgres_data_prod:/data -v $(pwd):/backup \
  busybox tar xzf /backup/postgres_data_20251110.tar.gz -C /data

# é‡å¯æœåŠ¡
docker-compose -f docker-compose.prod.yml start
```

---

## 9. è¿ç»´æ‰‹å†Œ

### 9.1 å¸¸è§é—®é¢˜æ’æŸ¥

#### Web æœåŠ¡æ— æ³•å¯åŠ¨

**ç—‡çŠ¶**ï¼š`docker-compose ps` æ˜¾ç¤º web å®¹å™¨çŠ¶æ€ä¸º `Restarting` æˆ– `Exited`

**æ’æŸ¥æ­¥éª¤**ï¼š
```bash
# 1. æŸ¥çœ‹æ—¥å¿—
docker-compose -f docker-compose.prod.yml logs web

# 2. æ£€æŸ¥å¥åº·æ£€æŸ¥
curl http://localhost:8000/healthz

# 3. å¸¸è§åŸå› 
# - æ•°æ®åº“è¿æ¥å¤±è´¥ï¼šæ£€æŸ¥ DATABASE_URL é…ç½®
# - è¿ç§»æœªæ‰§è¡Œï¼šè¿è¡Œ alembic upgrade head
# - ç«¯å£è¢«å ç”¨ï¼šlsof -i :8000
# - ç¯å¢ƒå˜é‡ç¼ºå¤±ï¼šæ£€æŸ¥ .env.prod æ–‡ä»¶
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# é‡æ–°åˆå§‹åŒ–æ•°æ®åº“
docker-compose -f docker-compose.prod.yml exec web alembic upgrade head

# é‡å¯æœåŠ¡
docker-compose -f docker-compose.prod.yml restart web
```

#### Worker ä»»åŠ¡ç§¯å‹

**ç—‡çŠ¶**ï¼šç®¡ç†å°æ˜¾ç¤ºé˜Ÿåˆ—ä»»åŠ¡æ•°æŒç»­å¢é•¿

**æ’æŸ¥æ­¥éª¤**ï¼š
```bash
# 1. æŸ¥çœ‹ Worker çŠ¶æ€
docker-compose -f docker-compose.prod.yml exec worker \
  celery -A src.tasks.celery_app inspect active

# 2. æŸ¥çœ‹å¤±è´¥ä»»åŠ¡
docker-compose -f docker-compose.prod.yml exec worker \
  celery -A src.tasks.celery_app inspect reserved

# 3. æŸ¥çœ‹ Worker æ—¥å¿—
docker-compose -f docker-compose.prod.yml logs worker | grep ERROR
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å¢åŠ  Worker å¹¶å‘æ•°ï¼ˆä¸´æ—¶ï¼‰
docker-compose -f docker-compose.prod.yml exec worker \
  celery -A src.tasks.celery_app control pool_grow 2

# æˆ–ä¿®æ”¹ docker-compose.prod.ymlï¼Œå¢åŠ  --concurrency å‚æ•°åé‡å¯

# æ¸…é™¤å¤±è´¥ä»»åŠ¡ï¼ˆæ…ç”¨ï¼‰
docker-compose -f docker-compose.prod.yml exec worker \
  celery -A src.tasks.celery_app purge
```

#### é‚®ä»¶å‘é€å¤±è´¥

**ç—‡çŠ¶**ï¼šdelivery_log æ˜¾ç¤ºå¤§é‡å¤±è´¥è®°å½•

**æ’æŸ¥æ­¥éª¤**ï¼š
```bash
# 1. æŸ¥çœ‹ SMTP é…ç½®
docker-compose -f docker-compose.prod.yml exec web env | grep SMTP

# 2. æµ‹è¯• SMTP è¿æ¥
docker-compose -f docker-compose.prod.yml exec web python -c "
from src.mailer.smtp_client import SMTPClient
import asyncio
async def test():
    client = SMTPClient()
    await client.send_email('test@example.com', 'Test', '<p>Test</p>')
asyncio.run(test())
"

# 3. æ£€æŸ¥æ”¶ä»¶äººç™½åå•
docker-compose -f docker-compose.prod.yml exec web python scripts/list_recipients.py
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- SMTP æˆæƒç è¿‡æœŸï¼šæ›´æ–° `SMTP_PASS` ç¯å¢ƒå˜é‡
- è¢«é™é€Ÿï¼šé™ä½ `MAIL_RATE_LIMIT_PER_SEC` é…ç½®
- æ”¶ä»¶äººåœ°å€é”™è¯¯ï¼šç®¡ç†å°ä¿®æ­£æˆ–ç§»é™¤

#### ç£ç›˜ç©ºé—´ä¸è¶³

**æ’æŸ¥æ­¥éª¤**ï¼š
```bash
# 1. æŸ¥çœ‹ç£ç›˜ä½¿ç”¨
df -h

# 2. æŸ¥çœ‹ Docker å·å ç”¨
docker system df -v

# 3. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶å¤§å°
du -sh /var/lib/docker/containers/*/*-json.log
```

**æ¸…ç†æ–¹æ¡ˆ**ï¼š
```bash
# æ¸…ç†æœªä½¿ç”¨çš„é•œåƒ
docker image prune -a

# æ¸…ç†æœªä½¿ç”¨çš„å·
docker volume prune

# æ¸…ç†æ—§æ—¥å¿—
docker-compose -f docker-compose.prod.yml exec postgres \
  psql -U fin_user -d fin_daily_report -c "DELETE FROM delivery_log WHERE created_at < NOW() - INTERVAL '90 days';"
```

### 9.2 æ—¥å¸¸è¿ç»´å‘½ä»¤

**æœåŠ¡ç®¡ç†**ï¼š
```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose -f docker-compose.prod.yml up -d

# åœæ­¢æ‰€æœ‰æœåŠ¡
docker-compose -f docker-compose.prod.yml down

# é‡å¯ç‰¹å®šæœåŠ¡
docker-compose -f docker-compose.prod.yml restart web worker

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose -f docker-compose.prod.yml ps

# æŸ¥çœ‹èµ„æºä½¿ç”¨
docker stats
```

**æ»šåŠ¨æ›´æ–°ï¼ˆé›¶åœæœºï¼‰**ï¼š
```bash
# 1. æ‹‰å–æ–°é•œåƒ
docker-compose -f docker-compose.prod.yml pull

# 2. é€ä¸ªé‡å¯æœåŠ¡
docker-compose -f docker-compose.prod.yml up -d --no-deps --build web
docker-compose -f docker-compose.prod.yml up -d --no-deps --build worker
docker-compose -f docker-compose.prod.yml up -d --no-deps --build beat

# 3. éªŒè¯æœåŠ¡
curl http://localhost:8000/healthz
```

**æ•°æ®åº“ç®¡ç†**ï¼š
```bash
# è¿›å…¥æ•°æ®åº“
docker-compose -f docker-compose.prod.yml exec postgres \
  psql -U fin_user -d fin_daily_report

# æŸ¥çœ‹è¡¨å¤§å°
docker-compose -f docker-compose.prod.yml exec postgres \
  psql -U fin_user -d fin_daily_report -c "\dt+"

# æ¸…ç†æ—§æ•°æ®
docker-compose -f docker-compose.prod.yml exec postgres \
  psql -U fin_user -d fin_daily_report -c "DELETE FROM articles WHERE created_at < NOW() - INTERVAL '180 days';"
```

**Redis ç®¡ç†**ï¼š
```bash
# è¿›å…¥ Redis CLI
docker-compose -f docker-compose.prod.yml exec redis redis-cli

# æŸ¥çœ‹å†…å­˜ä½¿ç”¨
docker-compose -f docker-compose.prod.yml exec redis redis-cli info memory

# æ¸…ç©ºç¼“å­˜ï¼ˆæ…ç”¨ï¼‰
docker-compose -f docker-compose.prod.yml exec redis redis-cli FLUSHDB
```

### 9.3 æ€§èƒ½ä¼˜åŒ–å»ºè®®

**2C/2G æœåŠ¡å™¨ä¼˜åŒ–é…ç½®**ï¼š

1. **é™åˆ¶ Playwright å¹¶å‘**ï¼š
   ```bash
   # .env.prod
   CRAWL_CONCURRENCY_WEB=1  # é™ä½åˆ° 1ï¼Œé¿å…å†…å­˜æº¢å‡º
   ```

2. **ä¼˜åŒ– Celery Worker**ï¼š
   ```yaml
   # docker-compose.prod.yml
   worker:
     command: celery -A src.tasks.celery_app worker
              --loglevel=info
              --concurrency=2
              --max-tasks-per-child=50  # é˜²æ­¢å†…å­˜æ³„æ¼
              --prefetch-multiplier=1   # å‡å°‘é¢„å–
   ```

3. **å¯ç”¨ Redis LRU æ·˜æ±°**ï¼š
   ```yaml
   redis:
     command: redis-server
              --maxmemory 256mb
              --maxmemory-policy allkeys-lru
   ```

4. **PostgreSQL è¿æ¥æ± **ï¼š
   ```python
   # src/db/session.py
   engine = create_engine(
       settings.DATABASE_URL,
       pool_size=5,  # é™åˆ¶è¿æ¥æ•°
       max_overflow=10,
       pool_pre_ping=True
   )
   ```

---

## 10. å®‰å…¨åŠ å›º

### 10.1 æœºå¯†ç®¡ç†

**Docker Secretsï¼ˆæ¨èï¼‰**ï¼š

```yaml
# docker-compose.prod.yml
secrets:
  postgres_password:
    file: ./secrets/postgres_password.txt
  smtp_password:
    file: ./secrets/smtp_password.txt

services:
  web:
    secrets:
      - postgres_password
      - smtp_password
    environment:
      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password
      SMTP_PASS_FILE: /run/secrets/smtp_password
```

ä¿®æ”¹ `src/config/settings.py` æ”¯æŒæ–‡ä»¶è¯»å–ï¼š

```python
@validator("POSTGRES_PASSWORD", pre=True)
def load_postgres_password(cls, v):
    if file_path := os.getenv("POSTGRES_PASSWORD_FILE"):
        return Path(file_path).read_text().strip()
    return v
```

### 10.2 ç½‘ç»œéš”ç¦»

```yaml
# docker-compose.prod.yml
networks:
  frontend:  # Web å¯¹å¤–ç½‘ç»œ
  backend:   # æ•°æ®åº“å†…éƒ¨ç½‘ç»œ

services:
  web:
    networks:
      - frontend
      - backend
    ports:
      - "8000:8000"

  postgres:
    networks:
      - backend  # ä»…å†…éƒ¨è®¿é—®
    # ç§»é™¤ ports é…ç½®ï¼Œç¦æ­¢å¤–éƒ¨è®¿é—®
```

### 10.3 åå‘ä»£ç†ï¼ˆNginxï¼‰

**é…ç½®ç¤ºä¾‹** (`nginx/finrep.conf`)ï¼š

```nginx
server {
    listen 80;
    server_name your-domain.com;

    # HTTPS é‡å®šå‘
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name your-domain.com;

    ssl_certificate /etc/nginx/certs/fullchain.pem;
    ssl_certificate_key /etc/nginx/certs/privkey.pem;

    # å®‰å…¨å¤´
    add_header Strict-Transport-Security "max-age=31536000" always;
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;

    # é™æ€èµ„æºç¼“å­˜
    location /static/ {
        alias /app/src/web/static/;
        expires 7d;
        add_header Cache-Control "public, immutable";
    }

    # ä»£ç†åˆ° Web æœåŠ¡
    location / {
        proxy_pass http://web:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # WebSocket æ”¯æŒï¼ˆå¦‚éœ€è¦ï¼‰
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }

    # é™æµ
    limit_req_zone $binary_remote_addr zone=login_limit:10m rate=5r/m;
    location /login {
        limit_req zone=login_limit burst=2 nodelay;
        proxy_pass http://web:8000;
    }
}
```

**æ·»åŠ åˆ° docker-compose.prod.yml**ï¼š

```yaml
services:
  nginx:
    image: nginx:alpine
    container_name: finrep_nginx_prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/finrep.conf:/etc/nginx/conf.d/default.conf
      - ./nginx/certs:/etc/nginx/certs
      - ./src/web/static:/app/src/web/static:ro
    depends_on:
      - web
    restart: unless-stopped
```

---

## 11. éªŒæ”¶æ ‡å‡†ï¼ˆPhase 3A å®Œæˆæ ‡å‡†ï¼‰

### 11.1 åŠŸèƒ½éªŒæ”¶

- [ ] **ä¸€é”®éƒ¨ç½²**ï¼šå¼€å‘ç¯å¢ƒ `docker-compose.dev.yml up -d` åæ‰€æœ‰å®¹å™¨å¥åº·
- [ ] **ç”Ÿäº§éƒ¨ç½²**ï¼š`docker-compose.prod.yml` åœ¨ 2C/2G æœåŠ¡å™¨æˆåŠŸè¿è¡Œ â‰¥72 å°æ—¶
- [ ] **å¥åº·æ£€æŸ¥**ï¼š`/healthz` æ¥å£è¿”å› 200ï¼ŒåŒ…å« Postgres/Redis/Celery çŠ¶æ€
- [ ] **å®šæ—¶ä»»åŠ¡**ï¼šCelery Beat åœ¨ 06:00 è‡ªåŠ¨è§¦å‘æ—¥æŠ¥æµç¨‹
- [ ] **é‚®ä»¶æŠ•é€’**ï¼š06:20 å‰å®Œæˆé‚®ä»¶å‘é€ï¼Œ`delivery_log` è®°å½•å®Œæ•´
- [ ] **æ•°æ®æŒä¹…åŒ–**ï¼šå®¹å™¨é‡å¯åæ•°æ®ä¸ä¸¢å¤±ï¼ˆPostgreSQL å·ï¼‰
- [ ] **æ—¥å¿—æ»šåŠ¨**ï¼šç”Ÿäº§ç¯å¢ƒæ—¥å¿—æ–‡ä»¶è‡ªåŠ¨è½®è½¬ï¼Œä¸è¶…è¿‡ 150MB

### 11.2 æ€§èƒ½éªŒæ”¶

- [ ] **èµ„æºé™åˆ¶**ï¼šWeb â‰¤512MBï¼ŒWorker â‰¤1GBï¼ŒBeat â‰¤256MB
- [ ] **å¹¶å‘å¤„ç†**ï¼šCelery Worker åŒæ—¶å¤„ç† 2 ä¸ªä»»åŠ¡ä¸ OOM
- [ ] **å“åº”æ—¶é—´**ï¼š`/healthz` æ¥å£å“åº”æ—¶é—´ <500msï¼ˆP95ï¼‰
- [ ] **å†…å­˜ç¨³å®šæ€§**ï¼šè¿è¡Œ 3 å¤©åå†…å­˜å¢é•¿ <10%

### 11.3 å¯è§‚æµ‹æ€§éªŒæ”¶

- [ ] **å®¹å™¨ç›‘æ§**ï¼š`docker stats` æ˜¾ç¤ºæ‰€æœ‰å®¹å™¨èµ„æºä½¿ç”¨
- [ ] **æ—¥å¿—æŸ¥è¯¢**ï¼š`docker-compose logs` å¯æŸ¥è¯¢æœ€è¿‘ 7 å¤©æ—¥å¿—
- [ ] **ç³»ç»Ÿç›‘æ§**ï¼šç®¡ç†å° `/admin/status` æ˜¾ç¤ºå®æ—¶æŒ‡æ ‡ä¸è¶‹åŠ¿å›¾
- [ ] **å‘Šè­¦æœºåˆ¶**ï¼šå®¹å™¨å´©æºƒåè‡ªåŠ¨é‡å¯ï¼ˆrestart: unless-stoppedï¼‰

### 11.4 å®‰å…¨éªŒæ”¶

- [ ] **æœºå¯†éš”ç¦»**ï¼š`.env.prod` ä¸åŒ…å«åœ¨é•œåƒä¸­
- [ ] **é root è¿è¡Œ**ï¼šåº”ç”¨å®¹å™¨ä½¿ç”¨éç‰¹æƒç”¨æˆ·ï¼ˆUID 1000ï¼‰
- [ ] **ç½‘ç»œéš”ç¦»**ï¼šæ•°æ®åº“å®¹å™¨ä¸æš´éœ²å¤–éƒ¨ç«¯å£ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
- [ ] **HTTPS æ”¯æŒ**ï¼šNginx åå‘ä»£ç†é…ç½® TLSï¼ˆå¯é€‰ï¼Œæ¨èç”Ÿäº§ç¯å¢ƒï¼‰

---

## 12. äº‘ç«¯éƒ¨ç½²ç­–ç•¥ï¼ˆé˜¿é‡Œäº‘ 4C8G ECS ç¯å¢ƒï¼‰

### 12.0 éƒ¨ç½²ç›®æ ‡ä¸ç¯å¢ƒè¯´æ˜

**ç›®æ ‡**ï¼šå¿«é€Ÿéƒ¨ç½²åˆ°é˜¿é‡Œäº‘ 4æ ¸8G ECSï¼Œæ”¯æŒå°‘é‡ç”¨æˆ·ï¼ˆ<50äººï¼‰ä½¿ç”¨ï¼Œééšç§æ•æ„Ÿæ•°æ®

**ç¯å¢ƒèµ„æº**ï¼š
- é˜¿é‡Œäº‘ ECSï¼š4æ ¸8G å†…å­˜ï¼Œ40GB+ ç£ç›˜
- ç”¨æˆ·è§„æ¨¡ï¼šç®¡ç†å‘˜ 1-5äººï¼Œé‚®ä»¶æ”¶ä»¶äºº <50äºº
- æ•°æ®å®‰å…¨çº§åˆ«ï¼šééšç§æ•æ„Ÿï¼Œå…è®¸æ˜æ–‡é…ç½®ç®€åŒ–éƒ¨ç½²

**éƒ¨ç½²åŸåˆ™**ï¼š
- âœ… **P0 - ç«‹å³è§£å†³**ï¼šé˜»å¡éƒ¨ç½²çš„é—®é¢˜ï¼Œå¿…é¡»åœ¨ä¸Šçº¿å‰å®Œæˆ
- â³ **P1 - åç»­ä¼˜åŒ–**ï¼šä¸å½±å“åŸºæœ¬åŠŸèƒ½ï¼Œå¯ä»¥ä¸Šçº¿åé€æ­¥æ”¹è¿›
- ğŸ”„ **P2 - é•¿æœŸè§„åˆ’**ï¼šå®‰å…¨åŠ å›ºã€é«˜å¯ç”¨ç­‰ä¼ä¸šçº§ç‰¹æ€§

---

### 12.1 æœ€å°å¯è¡Œéƒ¨ç½²æ–¹æ¡ˆï¼ˆMVP Deployï¼‰- 3å¤©ä¸Šçº¿

#### é˜¶æ®µç›®æ ‡
åœ¨ **3å¤©å†…** å®Œæˆéƒ¨ç½²ï¼Œç³»ç»Ÿèƒ½å¤Ÿï¼š
- âœ… åœ¨ ECS ä¸Šé€šè¿‡ Docker Compose ä¸€é”®å¯åŠ¨
- âœ… å®šæ—¶é‡‡é›†ä¿¡æ¯æºå¹¶ç”Ÿæˆæ—¥æŠ¥
- âœ… å‘é€é‚®ä»¶ç»™æ”¶ä»¶äººåˆ—è¡¨
- âœ… ç®¡ç†å‘˜å¯é€šè¿‡ Web ç•Œé¢ç®¡ç†ç³»ç»Ÿ
- âœ… åŸºæœ¬çš„æ—¥å¿—è®°å½•å’Œé”™è¯¯è¿½è¸ª

#### å¿«é€Ÿéƒ¨ç½²æ£€æŸ¥æ¸…å•

**Day 1 - å®¹å™¨åŒ–åŸºç¡€ï¼ˆP0ï¼‰**
```yaml
- [ ] ç¼–å†™åŸºç¡€ Dockerfileï¼ˆåŸºäº python:3.11-slim + playwrightï¼‰
- [ ] åˆ›å»ºç®€åŒ–ç‰ˆ docker-compose.prod.ymlï¼ˆweb + worker + beat + postgres + redisï¼‰
- [ ] é…ç½® .env.prod ç¯å¢ƒå˜é‡ï¼ˆæ˜æ–‡é…ç½®ï¼Œç®€åŒ–éƒ¨ç½²ï¼‰
- [ ] æµ‹è¯•æœ¬åœ° Docker ç¯å¢ƒå¯åŠ¨æˆåŠŸ
```

**Day 2 - ECS éƒ¨ç½²ä¸è°ƒè¯•ï¼ˆP0ï¼‰**
```yaml
- [ ] åœ¨ ECS å®‰è£… Docker + Docker Compose
- [ ] ä¸Šä¼ ä»£ç å’Œé…ç½®æ–‡ä»¶åˆ° ECS
- [ ] å¯åŠ¨æœåŠ¡å¹¶éªŒè¯å„ç»„ä»¶å¥åº·çŠ¶æ€
- [ ] é…ç½®é˜²ç«å¢™å¼€æ”¾ 8000 ç«¯å£
- [ ] æ‰§è¡Œæ•°æ®åº“è¿ç§»å’Œåˆå§‹æ•°æ®å¯¼å…¥
```

**Day 3 - åŠŸèƒ½éªŒè¯ä¸ä¼˜åŒ–ï¼ˆP0ï¼‰**
```yaml
- [ ] æ‰‹åŠ¨è§¦å‘é‡‡é›†ä»»åŠ¡ï¼ŒéªŒè¯åŠ¨æ€é‡‡é›†åŠŸèƒ½
- [ ] éªŒè¯å®šæ—¶ä»»åŠ¡è‡ªåŠ¨æ‰§è¡Œï¼ˆCelery Beatï¼‰
- [ ] æµ‹è¯•é‚®ä»¶å‘é€åŠŸèƒ½
- [ ] é…ç½®åŸŸåè§£æï¼ˆå¯é€‰ï¼‰
- [ ] æ·»åŠ åŸºæœ¬çš„ç›‘æ§è„šæœ¬ï¼ˆdocker statsï¼‰
```

---

### 12.2 P0 ä»»åŠ¡è¯¦è§£ï¼ˆé˜»å¡éƒ¨ç½²ï¼Œå¿…é¡»è§£å†³ï¼‰

#### P0-1ï¼šå®Œæˆåº”ç”¨å®¹å™¨åŒ– ã€Day 1ï¼Œ4å°æ—¶ã€‘

**ç°çŠ¶é—®é¢˜**ï¼š
- åº”ç”¨ä¾èµ– `scripts/start_all.sh` åœ¨æœ¬åœ°è™šæ‹Ÿç¯å¢ƒå¯åŠ¨
- äº‘ç«¯æ— æ³•ä½¿ç”¨ WSL å’Œäº¤äº’å¼ç¯å¢ƒ

**æœ€å°åŒ–æ–¹æ¡ˆ**ï¼ˆè·³è¿‡å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–ï¼‰ï¼š

### 12.1 å®¹å™¨åŒ–æœªå®Œæˆé£é™© ã€P0 - å¿…é¡»è§£å†³ã€‘

**ç°çŠ¶é—®é¢˜**ï¼š
- `docker-compose.yml` ä»…å¯åŠ¨ Postgres/Redisï¼ŒWeb/Celery ä»ä¾èµ– `scripts/start_all.sh` åœ¨æœ¬æœº `.venv` ä¸­ç”¨ `nohup + uvicorn --reload` æ‹‰èµ·
- äº‘ç«¯èŠ‚ç‚¹æ— æ³•ä¾èµ–äº¤äº’å¼è™šæ‹Ÿç¯å¢ƒï¼Œ`--reload` å’Œ PID æ–‡ä»¶ç®¡ç†ä¸é€‚ç”¨äºç”Ÿäº§ç¯å¢ƒ

**æ”¹è¿›æ–¹æ¡ˆ**ï¼š
```yaml
# ä»»åŠ¡æ¸…å•
- [ ] ç¼–å†™å¤šé˜¶æ®µ Dockerfileï¼ŒåŒ…å« poetry install + playwright install chromium
- [ ] åœ¨ docker-compose.prod.yml ä¸­æ‹†åˆ†æœåŠ¡ï¼š
      - web: gunicorn -k uvicorn.workers.UvicornWorker --workers 2
      - celery-worker: celery worker --concurrency=2
      - celery-beat: celery beat
      - scheduler: ç‹¬ç«‹å®šæ—¶è°ƒåº¦æœåŠ¡ï¼ˆå¯é€‰ï¼‰
- [ ] ç§»é™¤ scripts/start_all.sh å¯¹ nohup/PID æ–‡ä»¶çš„ä¾èµ–
- [ ] ä¸ºæ¯ä¸ªæœåŠ¡é…ç½®å¥åº·æ£€æŸ¥ä¸è‡ªåŠ¨é‡å¯ç­–ç•¥
```

**æ¶‰åŠæ–‡ä»¶**ï¼š
- `docker-compose.yml:2-31`
- `scripts/start_all.sh:7-140`

---

### 12.2 ä»£ç†é…ç½®ç¡¬ç¼–ç é£é™© ã€P0 - å¿…é¡»è§£å†³ã€‘

**ç°çŠ¶é—®é¢˜**ï¼š
- `.env.example` å°† `PLAYWRIGHT_PROXY` ç¡¬ç¼–ç ä¸º `http://127.0.0.1:7890`
- BrowserPool å’Œæ™ºèƒ½ä»£ç†ç­–ç•¥ç›´æ¥æ³¨å…¥è¯¥åœ°å€åˆ° Playwright ä¸Šä¸‹æ–‡
- äº‘ä¸Šå®¹å™¨è‹¥æ— åŒæœºä»£ç†ä¼šå¯¼è‡´æ‰€æœ‰å›½å¤–ç«™ç‚¹æŒ‚èµ·æˆ–è¶…æ—¶
- åŸŸåç™½åå•ç¡¬ç¼–ç åœ¨ä»£ç ä¸­ï¼Œæ— æ³•åŠ¨æ€æ›´æ–°

**æ”¹è¿›æ–¹æ¡ˆ**ï¼š
```yaml
# ä»»åŠ¡æ¸…å•
- [ ] ä¿®æ”¹ BrowserPool/ProxyStrategyï¼Œæ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡åŠ¨æ€é…ç½®ä»£ç†ï¼š
      - PLAYWRIGHT_PROXY_ENABLED=true/false
      - PLAYWRIGHT_PROXY_URLï¼ˆç•™ç©ºåˆ™ä¸ä½¿ç”¨ä»£ç†ï¼‰
      - PROXY_DOMESTIC_DOMAINSï¼ˆå›½å†…ç™½åå•åŸŸåï¼Œé€—å·åˆ†éš”ï¼‰
- [ ] å°†åŸŸåç™½åå•è¿ç§»åˆ°æ•°æ®åº“è¡¨ï¼ˆproxy_domain_rulesï¼‰ï¼š
      | id | domain         | use_proxy | priority |
      |----|----------------|-----------|----------|
      | 1  | *.cn          | false     | 100      |
      | 2  | *.baidu.com   | false     | 90       |
      | 3  | *             | true      | 0        |
- [ ] åœ¨ç®¡ç†åå°æ·»åŠ "ä»£ç†è§„åˆ™ç®¡ç†"é¡µé¢ï¼Œæ”¯æŒ CRUD æ“ä½œ
- [ ] æ›´æ–°æ–‡æ¡£ï¼Œè¯´æ˜ä¸åŒéƒ¨ç½²ç¯å¢ƒçš„ä»£ç†é…ç½®æ–¹æ¡ˆï¼š
      - æœ¬åœ°å¼€å‘: http://127.0.0.1:7890
      - äº‘ç«¯ VPC: http://proxy.internal:8080
      - æ— ä»£ç†ç¯å¢ƒ: ç•™ç©ºæˆ– false
```

**æ¶‰åŠæ–‡ä»¶**ï¼š
- `.env.example:29-35`
- `src/crawlers/browser_pool.py:72-104`
- `src/crawlers/proxy_strategy.py:23-145`

---

### 12.3 Playwright è¿è¡Œæ—¶ä¾èµ–ç¼ºå¤± ã€P0 - å¿…é¡»è§£å†³ã€‘

**ç°çŠ¶é—®é¢˜**ï¼š
- Dockerfile æœªå®‰è£… `playwright install-deps` éœ€è¦çš„ç³»ç»Ÿåº“ï¼ˆå­—ä½“/glib/nss ç­‰ï¼‰
- å®¹å™¨å¯åŠ¨æ—¶å› ç¼ºå°‘å…±äº«å†…å­˜æˆ– sandbox æƒé™å¯¼è‡´ Chromium å¯åŠ¨å¤±è´¥
- BrowserPool å¼ºåˆ¶ä½¿ç”¨ `--no-sandbox/--disable-dev-shm-usage` å­˜åœ¨å®‰å…¨éšæ‚£

**æ”¹è¿›æ–¹æ¡ˆ**ï¼š
```dockerfile
# Dockerfile æ”¹è¿›ç¤ºä¾‹
FROM mcr.microsoft.com/playwright/python:v1.40.0-jammy as base

# æˆ–ä½¿ç”¨è‡ªå®šä¹‰åŸºç¡€é•œåƒ
FROM python:3.11-slim
RUN apt-get update && apt-get install -y \
    libglib2.0-0 libnss3 libnspr4 libdbus-1-3 libatk1.0-0 \
    libatk-bridge2.0-0 libcups2 libdrm2 libxkbcommon0 \
    libxcomposite1 libxdamage1 libxfixes3 libxrandr2 \
    libgbm1 libpango-1.0-0 libcairo2 libasound2 \
    fonts-wqy-zenhei && \
    playwright install chromium && \
    playwright install-deps && \
    rm -rf /var/lib/apt/lists/*

# é…ç½®å…±äº«å†…å­˜
RUN mkdir -p /dev/shm && chmod 1777 /dev/shm
```

```yaml
# docker-compose.prod.yml é…ç½®
services:
  worker:
    shm_size: '256mb'  # å¢åŠ å…±äº«å†…å­˜
    security_opt:
      - seccomp:unconfined  # æ”¾å®½ seccomp é™åˆ¶ï¼ˆä»…åœ¨å¿…è¦æ—¶ï¼‰
    # æˆ–ä½¿ç”¨é root ç”¨æˆ· + CAP_SYS_ADMIN
    cap_add:
      - SYS_ADMIN
    user: "1000:1000"
```

**ä»»åŠ¡æ¸…å•**ï¼š
```yaml
- [ ] æ›´æ–° Dockerfileï¼Œé›†æˆå®˜æ–¹ Playwright åŸºç¡€é•œåƒæˆ–å®Œæ•´å®‰è£…ä¾èµ–
- [ ] é…ç½®å®¹å™¨ shm_size å’Œ seccomp ç­–ç•¥
- [ ] æµ‹è¯•åœ¨æ—  --no-sandbox æ¨¡å¼ä¸‹è¿è¡Œï¼ˆä¼˜å…ˆæ¨èï¼‰
- [ ] æ·»åŠ å¥åº·æ£€æŸ¥è„šæœ¬ï¼ŒéªŒè¯ Chromium å¯æ­£å¸¸å¯åŠ¨
```

**æ¶‰åŠæ–‡ä»¶**ï¼š
- `Dockerfile` ï¼ˆå¾…åˆ›å»ºå®Œæ•´ç‰ˆæœ¬ï¼‰
- `src/crawlers/browser_pool.py:58-66`

---

### 12.4 æ•°æ®åº“è¿æ¥æ± é…ç½®é”™è¯¯ ã€P1 - é«˜ä¼˜å…ˆçº§ã€‘

**ç°çŠ¶é—®é¢˜**ï¼š
- `src/db/session.py` å¼ºåˆ¶ä½¿ç”¨ `NullPool`ï¼Œæ¯ä¸ªè¯·æ±‚æ–°å»º TCP è¿æ¥
- å¤šè¿›ç¨‹ FastAPI/Celery åœºæ™¯ä¸‹ä¼šè€—å°½æ‰˜ç®¡æ•°æ®åº“è¿æ¥æ•°
- æœªé…ç½®è¿æ¥æ± å‚æ•°ï¼ˆ`pool_size`/`max_overflow`ï¼‰

**æ”¹è¿›æ–¹æ¡ˆ**ï¼š
```python
# src/db/session.py æ”¹è¿›
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool
from src.config.settings import settings

# æ ¹æ®ç¯å¢ƒé€‰æ‹©è¿æ¥æ± ç­–ç•¥
if settings.ENV == "production":
    engine = create_engine(
        settings.DATABASE_URL,
        poolclass=QueuePool,
        pool_size=5,          # åŸºç¡€è¿æ¥æ•°
        max_overflow=10,      # æœ€å¤§æº¢å‡ºè¿æ¥
        pool_timeout=30,      # è¿æ¥è¶…æ—¶
        pool_recycle=3600,    # è¿æ¥å›æ”¶æ—¶é—´ï¼ˆ1å°æ—¶ï¼‰
        pool_pre_ping=True,   # è¿æ¥å‰æ£€æŸ¥æœ‰æ•ˆæ€§
        echo=False
    )
else:
    # å¼€å‘ç¯å¢ƒä¿æŒåŸæœ‰é…ç½®
    engine = create_engine(
        settings.DATABASE_URL,
        poolclass=NullPool,
        echo=True
    )
```

**ä»»åŠ¡æ¸…å•**ï¼š
```yaml
- [ ] ä¿®æ”¹ src/db/session.pyï¼Œæ ¹æ® ENV ç¯å¢ƒå˜é‡åŠ¨æ€é€‰æ‹©è¿æ¥æ± 
- [ ] ä¸ºç”Ÿäº§ç¯å¢ƒé…ç½® QueuePool å‚æ•°ï¼ˆè€ƒè™‘ 2C/2G èµ„æºé™åˆ¶ï¼‰
- [ ] å¯é€‰ï¼šåœ¨æ•°æ®åº“å‰éƒ¨ç½² PgBouncer è¿æ¥æ± ä»£ç†
- [ ] ç›‘æ§æ•°æ®åº“è¿æ¥æ•°ï¼Œæ·»åŠ å‘Šè­¦è§„åˆ™ï¼ˆ>80% è§¦å‘ï¼‰
```

**æ¶‰åŠæ–‡ä»¶**ï¼š
- `src/db/session.py:13-22`

---

### 12.5 æ—¥å¿—ä¸è°ƒåº¦çŠ¶æ€æŒä¹…åŒ–ç¼ºå¤± ã€P1 - é«˜ä¼˜å…ˆçº§ã€‘

**ç°çŠ¶é—®é¢˜**ï¼š
- Loguru é»˜è®¤å†™ `logs/app_*.log` ç­‰æœ¬åœ°æ–‡ä»¶ï¼Œå®¹å™¨é‡å¯åä¸¢å¤±
- `start_all.sh` åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.pids` æ–‡ä»¶
- `celerybeat-schedule.db` å­˜å‚¨åœ¨å®¹å™¨å†…ï¼Œæ— æ³•æ¨ªå‘æ‰©å±•

**æ”¹è¿›æ–¹æ¡ˆ**ï¼š
```python
# æ–¹æ¡ˆä¸€ï¼šæ—¥å¿—è¾“å‡ºåˆ° STDOUTï¼ˆæ¨èï¼‰
from loguru import logger
import sys

logger.remove()  # ç§»é™¤é»˜è®¤å¤„ç†å™¨
logger.add(
    sys.stdout,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan> - <level>{message}</level>",
    level="INFO" if settings.ENV == "production" else "DEBUG"
)

# æ–¹æ¡ˆäºŒï¼šé›†ä¸­æ—¥å¿—ï¼ˆELK/CloudWatchï¼‰
logger.add(
    "syslog://logstash.internal:5140",  # Logstash æ¥æ”¶ç«¯
    format="{message}",
    serialize=True  # JSON æ ¼å¼
)
```

```yaml
# docker-compose.prod.yml æ—¥å¿—é…ç½®
services:
  web:
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
      # æˆ–ä½¿ç”¨ fluentd/syslog driver
      # driver: "fluentd"
      # options:
      #   fluentd-address: "localhost:24224"
```

```yaml
# Celery Beat æŒä¹…åŒ–
services:
  beat:
    command: celery -A src.tasks.celery_app beat --schedule /data/celerybeat-schedule.db
    volumes:
      - beat_schedule:/data  # æŒä¹…åŒ–å·
volumes:
  beat_schedule:
```

**ä»»åŠ¡æ¸…å•**ï¼š
```yaml
- [ ] ä¿®æ”¹ src/utils/logger.pyï¼Œç”Ÿäº§ç¯å¢ƒè¾“å‡ºåˆ° STDOUT
- [ ] ç§»é™¤ scripts/start_all.sh å¯¹ .pids æ–‡ä»¶çš„ä¾èµ–
- [ ] é…ç½® Celery Beat ä½¿ç”¨æŒä¹…åŒ–å·å­˜å‚¨ schedule
- [ ] æ·»åŠ æ—¥å¿—è½®è½¬ä¸å½’æ¡£ç­–ç•¥ï¼ˆä¿ç•™ 30 å¤©ï¼‰
- [ ] å¯é€‰ï¼šé›†æˆ ELK Stack æˆ–äº‘å‚å•†æ—¥å¿—æœåŠ¡
```

**æ¶‰åŠæ–‡ä»¶**ï¼š
- `src/utils/logger.py:11-82`
- `scripts/start_all.sh` ï¼ˆå¾…ç§»é™¤ï¼‰
- `docker-compose.prod.yml`

---

### 12.6 å¤–éƒ¨ä¾èµ–ç½‘ç»œç­–ç•¥ç¼ºå¤± ã€P1 - é«˜ä¼˜å…ˆçº§ã€‘

**ç°çŠ¶é—®é¢˜**ï¼š
- LLM è·¯ç”±å™¨å¹¶å‘è®¿é—® DeepSeek/Qwen APIï¼ˆå›½å¤–åŸŸåï¼‰
- é‚®ä»¶å‘é€é€šè¿‡ SSL 465 ç«¯å£ï¼Œå¾ˆå¤šäº‘ä¾›åº”å•†é»˜è®¤å°ç¦
- æœªé…ç½®é‡è¯•ã€ç†”æ–­ä¸é™çº§ç­–ç•¥

**æ”¹è¿›æ–¹æ¡ˆ**ï¼š
```python
# src/nlp/provider_router.py æ”¹è¿›
import httpx
from tenacity import retry, stop_after_attempt, wait_exponential

class ProviderRouter:
    def __init__(self):
        # é…ç½®è¶…æ—¶ä¸é‡è¯•
        self.client = httpx.AsyncClient(
            timeout=httpx.Timeout(90.0, connect=10.0),
            limits=httpx.Limits(max_connections=10),
            transport=httpx.AsyncHTTPTransport(retries=3)
        )

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        reraise=True
    )
    async def call_provider(self, provider: str, prompt: str):
        try:
            response = await self.client.post(...)
            return response.json()
        except httpx.ConnectTimeout:
            logger.error(f"Provider {provider} connection timeout, check network policy")
            raise
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 429:  # Rate limit
                logger.warning(f"Provider {provider} rate limited, retrying...")
                raise
            else:
                return None  # é™çº§å¤„ç†
```

**ç½‘ç»œç­–ç•¥æ£€æŸ¥æ¸…å•**ï¼š
```yaml
- [ ] ç”³è¯·äº‘å‚å•†å‡ºç«™ç™½åå•ï¼š
      - api.deepseek.comï¼ˆDeepSeek APIï¼‰
      - dashscope.aliyuncs.comï¼ˆQwen APIï¼‰
      - smtp.exmail.qq.com:465ï¼ˆä¼ä¸šé‚®ç®±ï¼‰
- [ ] é…ç½® HTTP ä»£ç†æˆ– VPN è½¬å‘æœåŠ¡
- [ ] ä¸ºæ‰€æœ‰å¤–éƒ¨ API è°ƒç”¨æ·»åŠ  timeout/retry/circuit breaker
- [ ] åœ¨ç®¡ç†åå°æ·»åŠ "å¤–éƒ¨æœåŠ¡è¿é€šæ€§æµ‹è¯•"å·¥å…·
- [ ] ç›‘æ§å¤–éƒ¨ API æˆåŠŸç‡ï¼Œ<95% æ—¶è§¦å‘å‘Šè­¦
```

**æ¶‰åŠæ–‡ä»¶**ï¼š
- `src/nlp/provider_router.py:24-190`
- `src/mailer/smtp_client.py:34-123`

---

### 12.7 å®‰å…¨é…ç½®ä¸è¶³ ã€P1 - é«˜ä¼˜å…ˆçº§ã€‘

**ç°çŠ¶é—®é¢˜**ï¼š
- `ALLOWED_HOSTS`/`CORS_ORIGINS`/`JWT_SECRET_KEY` ä»æ˜¯ç¤ºä¾‹å€¼
- Web æ¨¡å—æœªé…ç½® HTTPS/åå‘ä»£ç†ä¿¡ä»»
- ç¯å¢ƒå˜é‡ä¸­ç›´æ¥å†…åµŒ API Key å’Œå¯†ç 

**æ”¹è¿›æ–¹æ¡ˆ**ï¼š

**1. å®‰å…¨é…ç½®å¼ºåŒ–**ï¼š
```python
# src/config/settings.py
class Settings(BaseSettings):
    # å¼ºåˆ¶ç”Ÿäº§ç¯å¢ƒè¦†ç›–
    ALLOWED_HOSTS: list[str] = Field(
        default=["*"] if ENV == "development" else [],
        description="å…è®¸çš„åŸŸååˆ—è¡¨ï¼Œç”Ÿäº§ç¯å¢ƒå¿…é¡»æ˜¾å¼é…ç½®"
    )

    CORS_ORIGINS: list[str] = Field(
        default=["*"] if ENV == "development" else [],
        description="CORS å…è®¸çš„æº"
    )

    JWT_SECRET_KEY: str = Field(
        ...,  # å¿…å¡«
        min_length=32,
        description="JWT ç­¾åå¯†é’¥ï¼Œè‡³å°‘ 32 å­—ç¬¦"
    )

    @validator("JWT_SECRET_KEY")
    def validate_jwt_secret(cls, v, values):
        if values.get("ENV") == "production" and v == "change-this-to-a-very-long-random-string":
            raise ValueError("ç”Ÿäº§ç¯å¢ƒå¿…é¡»æ›´æ¢ JWT_SECRET_KEY")
        return v
```

**2. å¯†é’¥ç®¡ç†ï¼ˆDocker Secretsï¼‰**ï¼š
```yaml
# docker-compose.prod.yml
secrets:
  postgres_password:
    file: ./secrets/postgres_password.txt
  deepseek_api_key:
    file: ./secrets/deepseek_api_key.txt
  smtp_password:
    file: ./secrets/smtp_password.txt

services:
  web:
    secrets:
      - postgres_password
      - deepseek_api_key
      - smtp_password
    environment:
      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password
      PROVIDER_DEEPSEEK_API_KEY_FILE: /run/secrets/deepseek_api_key
      SMTP_PASS_FILE: /run/secrets/smtp_password
```

```python
# src/config/settings.py æ”¯æŒæ–‡ä»¶è¯»å–
@validator("POSTGRES_PASSWORD", pre=True)
def load_from_file(cls, v):
    if file_path := os.getenv("POSTGRES_PASSWORD_FILE"):
        return Path(file_path).read_text().strip()
    return v
```

**3. åå‘ä»£ç†é…ç½®**ï¼š
```python
# src/web/app.py
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.middleware.httpsredirect import HTTPSRedirectMiddleware

if settings.ENV == "production":
    # å¼ºåˆ¶ HTTPS
    app.add_middleware(HTTPSRedirectMiddleware)

    # é™åˆ¶å…è®¸çš„ Host å¤´
    app.add_middleware(
        TrustedHostMiddleware,
        allowed_hosts=settings.ALLOWED_HOSTS
    )

    # ä¿¡ä»»åå‘ä»£ç†çš„ X-Forwarded-* å¤´
    app.middleware("http")(trust_forwarded_headers)
```

**ä»»åŠ¡æ¸…å•**ï¼š
```yaml
- [ ] æ›´æ–° src/config/settings.pyï¼Œç”Ÿäº§ç¯å¢ƒå¼ºåˆ¶éªŒè¯å®‰å…¨å‚æ•°
- [ ] å®ç° Docker Secrets æ”¯æŒï¼Œç§»é™¤ .env ä¸­çš„æ˜æ–‡å¯†é’¥
- [ ] æ·»åŠ  TrustedHostMiddleware å’Œ HTTPS é‡å®šå‘
- [ ] é…ç½® Nginx åå‘ä»£ç†ï¼Œç»ˆç»“ TLS
- [ ] åœ¨éƒ¨ç½²æ–‡æ¡£ä¸­å¼ºè°ƒç”Ÿäº§ç¯å¢ƒé…ç½®æ£€æŸ¥æ¸…å•
- [ ] ä½¿ç”¨å·¥å…·ç”Ÿæˆå¼ºå¯†ç ï¼ˆå¦‚ openssl rand -base64 32ï¼‰
```

**æ¶‰åŠæ–‡ä»¶**ï¼š
- `src/config/settings.py:94-111`
- `.env.example:6-19,76-84`
- `docker-compose.prod.yml`

---

### 12.8 æ”¹è¿›ä¼˜å…ˆçº§ä¸æ—¶é—´è§„åˆ’

| ä¼˜å…ˆçº§ | é£é™©é¡¹ | é¢„è®¡å·¥æ—¶ | ç›®æ ‡å®Œæˆé˜¶æ®µ |
|--------|--------|----------|--------------|
| **P0** | å®¹å™¨åŒ–æœªå®Œæˆ | 3 å¤© | Phase 3A Week 1 |
| **P0** | ä»£ç†é…ç½®ç¡¬ç¼–ç  | 2 å¤© | Phase 3A Week 1 |
| **P0** | Playwright ä¾èµ–ç¼ºå¤± | 1 å¤© | Phase 3A Week 1 |
| **P1** | æ•°æ®åº“è¿æ¥æ± é”™è¯¯ | 0.5 å¤© | Phase 3A Week 2 |
| **P1** | æ—¥å¿—æŒä¹…åŒ–ç¼ºå¤± | 1 å¤© | Phase 3A Week 2 |
| **P1** | å¤–éƒ¨ä¾èµ–ç½‘ç»œç­–ç•¥ | 1.5 å¤© | Phase 3A Week 2 |
| **P1** | å®‰å…¨é…ç½®ä¸è¶³ | 2 å¤© | Phase 3A Week 2 |

**Phase 3A è°ƒæ•´åéªŒæ”¶æ ‡å‡†**ï¼š
- [ ] æ‰€æœ‰ P0 é£é™©é¡¹å·²è§£å†³å¹¶é€šè¿‡æµ‹è¯•
- [ ] å®Œæ•´çš„ Docker é•œåƒå¯åœ¨æ— æœ¬åœ°è™šæ‹Ÿç¯å¢ƒçš„äº‘æœåŠ¡å™¨ä¸Šè¿è¡Œ
- [ ] ä»£ç†é…ç½®å¯é€šè¿‡ç¯å¢ƒå˜é‡åŠ¨æ€è°ƒæ•´ï¼ŒåŸŸåè§„åˆ™å­˜å‚¨åœ¨æ•°æ®åº“
- [ ] Playwright åœ¨æ ‡å‡†å®¹å™¨ç¯å¢ƒä¸­ç¨³å®šè¿è¡Œ â‰¥24 å°æ—¶
- [ ] æ•°æ®åº“è¿æ¥æ± åœ¨ç”Ÿäº§ç¯å¢ƒæœªå‡ºç°è¿æ¥è€—å°½
- [ ] æ‰€æœ‰ P1 é£é™©é¡¹å·²å®Œæˆæˆ–æœ‰æ˜ç¡®çš„ç¼“è§£æªæ–½
- [ ] é€šè¿‡å®‰å…¨æ‰«æï¼ˆæ— é«˜å±æ¼æ´ï¼‰ï¼Œå¯†é’¥å·²è¿ç§»åˆ° Secrets

---

## 13. ä¸‹ä¸€é˜¶æ®µè§„åˆ’ï¼ˆPhase 3B - åç»­å¢å¼ºï¼‰

### 13.1 ç›‘æ§å‘Šè­¦ï¼ˆPrometheus + Grafanaï¼‰

- é›†æˆ Prometheus Exporterï¼ˆPostgresã€Redisã€Celeryï¼‰
- Grafana ä»ªè¡¨ç›˜ï¼šé˜Ÿåˆ—ç§¯å‹ã€ä»»åŠ¡æˆåŠŸç‡ã€LLM è´¹ç”¨è¶‹åŠ¿
- å‘Šè­¦è§„åˆ™ï¼šå®¹å™¨å´©æºƒã€ä»»åŠ¡å¤±è´¥ç‡ >10%ã€ç£ç›˜ä½¿ç”¨ >80%

### 13.2 CI/CD æµæ°´çº¿

- GitHub Actions / GitLab CI è‡ªåŠ¨åŒ–æµ‹è¯•
- é•œåƒæ„å»ºä¸æ¼æ´æ‰«æï¼ˆTrivyï¼‰
- è‡ªåŠ¨éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒï¼ˆWebhook + docker-compose pullï¼‰

### 13.3 é«˜å¯ç”¨å¢å¼º

- PostgreSQL ä¸»ä»å¤åˆ¶ï¼ˆPatroni + etcdï¼‰
- Redis Sentinel å“¨å…µæ¨¡å¼
- Celery Worker å¤šå®ä¾‹è´Ÿè½½å‡è¡¡
- Nginx è´Ÿè½½å‡è¡¡ï¼ˆå¤š Web å®ä¾‹ï¼‰

### 13.4 ä¸šåŠ¡å¢å¼º

- å¤šç§Ÿæˆ·æ”¯æŒï¼ˆSaaS åŒ–ï¼‰
- WebSocket å®æ—¶æ¨é€ï¼ˆæŠ¥å‘Šç”Ÿæˆè¿›åº¦ï¼‰
- ç§»åŠ¨ç«¯é€‚é…ï¼ˆå“åº”å¼è®¾è®¡ï¼‰
- å¤šè¯­è¨€æ”¯æŒï¼ˆi18nï¼‰

---

## é™„å½•

### A. å®Œæ•´éƒ¨ç½²æ¸…å•

**ç›®å½•ç»“æ„**ï¼š
```
V4/
â”œâ”€â”€ docker-compose.dev.yml      # å¼€å‘ç¯å¢ƒç¼–æ’
â”œâ”€â”€ docker-compose.prod.yml     # ç”Ÿäº§ç¯å¢ƒç¼–æ’
â”œâ”€â”€ Dockerfile                  # åº”ç”¨é•œåƒæ„å»º
â”œâ”€â”€ .env.example                # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ .env.prod                   # ç”Ÿäº§ç¯å¢ƒé…ç½®ï¼ˆä¸æäº¤ï¼‰
â”œâ”€â”€ alembic.ini                 # æ•°æ®åº“è¿ç§»é…ç½®
â”œâ”€â”€ pyproject.toml              # Poetry ä¾èµ–ç®¡ç†
â”œâ”€â”€ src/                        # åº”ç”¨æºç 
â”œâ”€â”€ scripts/                    # è¿ç»´è„šæœ¬
â”‚   â”œâ”€â”€ backup_db.sh            # æ•°æ®åº“å¤‡ä»½
â”‚   â”œâ”€â”€ celery_health_check.sh  # Celery å¥åº·æ£€æŸ¥
â”‚   â””â”€â”€ seed_test_data.py       # æµ‹è¯•æ•°æ®å¯¼å…¥
â”œâ”€â”€ nginx/                      # Nginx é…ç½®ï¼ˆå¯é€‰ï¼‰
â”‚   â”œâ”€â”€ finrep.conf
â”‚   â””â”€â”€ certs/
â””â”€â”€ docs/                       # æ–‡æ¡£