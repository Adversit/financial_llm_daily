#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é‡ç½®å¤±è´¥æ–‡ç« çŠ¶æ€è„šæœ¬

å°†æŒ‡å®šæ—¥æœŸå†…çŠ¶æ€ä¸º failed çš„æ–‡ç« é‡ç½®ä¸º raw (å¾…å¤„ç†)çŠ¶æ€

ç”¨æ³•:
    python scripts/reset_failed_articles.py --date 2025-11-30
    python scripts/reset_failed_articles.py --date 2025-11-30 --dry-run  # åªæŸ¥çœ‹ä¸ä¿®æ”¹
"""

import argparse
from datetime import datetime, timedelta
from loguru import logger
from sqlalchemy import and_, or_

from src.db.session import SessionLocal
from src.models.article import Article, ProcessingStatus


def parse_date(date_str: str) -> tuple[datetime, datetime]:
    """
    è§£ææ—¥æœŸå­—ç¬¦ä¸²,è¿”å›å½“å¤©çš„å¼€å§‹å’Œç»“æŸæ—¶é—´

    Args:
        date_str: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)

    Returns:
        tuple[datetime, datetime]: (å¼€å§‹æ—¶é—´, ç»“æŸæ—¶é—´)
    """
    date = datetime.strptime(date_str, "%Y-%m-%d")
    start_time = date.replace(hour=0, minute=0, second=0, microsecond=0)
    end_time = start_time + timedelta(days=1)
    return start_time, end_time


def reset_failed_articles(date_str: str, dry_run: bool = False):
    """
    é‡ç½®æŒ‡å®šæ—¥æœŸçš„å¤±è´¥æ–‡ç« 

    Args:
        date_str: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
        dry_run: æ˜¯å¦åªæŸ¥çœ‹ä¸ä¿®æ”¹
    """
    start_time, end_time = parse_date(date_str)

    logger.info(f"{'[é¢„è§ˆæ¨¡å¼] ' if dry_run else ''}å¤„ç†æ—¥æœŸ: {date_str}")
    logger.info(f"æ—¶é—´èŒƒå›´: {start_time} ~ {end_time}")

    session = SessionLocal()
    try:
        # æŸ¥è¯¢æ¡ä»¶:
        # 1. published_at æˆ– fetched_at åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…
        # 2. processing_status = 'failed'
        query = session.query(Article).filter(
            and_(
                or_(
                    and_(Article.published_at >= start_time, Article.published_at < end_time),
                    and_(Article.fetched_at >= start_time, Article.fetched_at < end_time)
                ),
                Article.processing_status == ProcessingStatus.FAILED
            )
        )

        failed_articles = query.all()

        if not failed_articles:
            logger.info("âœ… æ²¡æœ‰æ‰¾åˆ°çŠ¶æ€ä¸º failed çš„æ–‡ç« ")
            return

        logger.info(f"æ‰¾åˆ° {len(failed_articles)} ç¯‡çŠ¶æ€ä¸º failed çš„æ–‡ç« :")
        print("\n" + "=" * 80)
        for i, article in enumerate(failed_articles, 1):
            print(f"{i}. [ID:{article.id}] {article.title[:60]}")
            print(f"   URL: {article.url}")
            print(f"   å‘å¸ƒæ—¶é—´: {article.published_at}")
            print(f"   é‡‡é›†æ—¶é—´: {article.fetched_at}")
            print(f"   å½“å‰çŠ¶æ€: {article.processing_status}")
        print("=" * 80 + "\n")

        if dry_run:
            logger.info("ğŸ” é¢„è§ˆæ¨¡å¼: ä¸æ‰§è¡Œä¿®æ”¹æ“ä½œ")
            logger.info(f"å¦‚éœ€ä¿®æ”¹,è¯·å»æ‰ --dry-run å‚æ•°é‡æ–°æ‰§è¡Œ")
            return

        # ç¡®è®¤ä¿®æ”¹
        logger.warning(f"å³å°†ä¿®æ”¹ {len(failed_articles)} ç¯‡æ–‡ç« çš„çŠ¶æ€: failed -> raw")

        # æ‰§è¡Œä¿®æ”¹
        for article in failed_articles:
            article.processing_status = ProcessingStatus.RAW

        session.commit()

        logger.success(f"âœ… æˆåŠŸä¿®æ”¹ {len(failed_articles)} ç¯‡æ–‡ç« çš„çŠ¶æ€ä¸º raw (å¾…å¤„ç†)")
        logger.info(f"æ¥ä¸‹æ¥å¯ä»¥è¿è¡Œ: python -m src.cli.run_once --step extract --date {date_str}")

    except Exception as e:
        session.rollback()
        logger.error(f"âŒ æ“ä½œå¤±è´¥: {e}", exc_info=True)
        raise
    finally:
        session.close()


def main():
    parser = argparse.ArgumentParser(description="é‡ç½®å¤±è´¥æ–‡ç« çŠ¶æ€")
    parser.add_argument(
        "--date",
        type=str,
        required=True,
        help="æŒ‡å®šæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD, ä¾‹å¦‚: 2025-11-30)"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="é¢„è§ˆæ¨¡å¼,åªæŸ¥çœ‹ä¸ä¿®æ”¹"
    )

    args = parser.parse_args()

    # éªŒè¯æ—¥æœŸæ ¼å¼
    try:
        datetime.strptime(args.date, "%Y-%m-%d")
    except ValueError:
        logger.error("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯,è¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼ (ä¾‹å¦‚: 2025-11-30)")
        return

    reset_failed_articles(args.date, args.dry_run)


if __name__ == "__main__":
    main()
