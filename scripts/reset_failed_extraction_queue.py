#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é‡ç½®å¤±è´¥çš„æŠ½å–é˜Ÿåˆ—çŠ¶æ€è„šæœ¬

å°†æŒ‡å®šæ—¥æœŸå†…çŠ¶æ€ä¸º failed çš„æŠ½å–é˜Ÿåˆ—é¡¹é‡ç½®ä¸º queued (å¾…å¤„ç†)çŠ¶æ€

ç”¨æ³•:
    python scripts/reset_failed_extraction_queue.py --date 2025-11-30
    python scripts/reset_failed_extraction_queue.py --date 2025-11-30 --dry-run  # åªæŸ¥çœ‹ä¸ä¿®æ”¹
"""

import argparse
from datetime import datetime, timedelta
from loguru import logger
from sqlalchemy import and_, or_

from src.db.session import SessionLocal
from src.models.article import Article
from src.models.extraction import ExtractionQueue, QueueStatus


def parse_date(date_str: str) -> tuple[datetime, datetime]:
    """
    è§£ææ—¥æœŸå­—ç¬¦ä¸²,è¿”å›å½“å¤©çš„å¼€å§‹å’Œç»“æŸæ—¶é—´

    Args:
        date_str: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)

    Returns:
        tuple[datetime, datetime]: (å¼€å§‹æ—¶é—´, ç»“æŸæ—¶é—´)
    """
    date = datetime.strptime(date_str, "%Y-%m-%d")
    start_time = date.replace(hour=0, minute=0, second=0, microsecond=0)
    end_time = start_time + timedelta(days=1)
    return start_time, end_time


def reset_failed_queue(date_str: str, dry_run: bool = False):
    """
    é‡ç½®æŒ‡å®šæ—¥æœŸçš„å¤±è´¥æŠ½å–é˜Ÿåˆ—é¡¹

    Args:
        date_str: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
        dry_run: æ˜¯å¦åªæŸ¥çœ‹ä¸ä¿®æ”¹
    """
    start_time, end_time = parse_date(date_str)

    logger.info(f"{'[é¢„è§ˆæ¨¡å¼] ' if dry_run else ''}å¤„ç†æ—¥æœŸ: {date_str}")
    logger.info(f"æ—¶é—´èŒƒå›´: {start_time} ~ {end_time}")

    session = SessionLocal()
    try:
        # æŸ¥è¯¢æ¡ä»¶:
        # 1. å…³è” articles è¡¨,ç­›é€‰ published_at æˆ– fetched_at åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…
        # 2. extraction_queue.status = 'failed'
        query = session.query(ExtractionQueue).join(
            Article, ExtractionQueue.article_id == Article.id
        ).filter(
            and_(
                or_(
                    and_(Article.published_at >= start_time, Article.published_at < end_time),
                    and_(Article.fetched_at >= start_time, Article.fetched_at < end_time)
                ),
                ExtractionQueue.status == QueueStatus.FAILED
            )
        )

        failed_queues = query.all()

        if not failed_queues:
            logger.info("âœ… æ²¡æœ‰æ‰¾åˆ°çŠ¶æ€ä¸º failed çš„æŠ½å–é˜Ÿåˆ—é¡¹")
            return

        logger.info(f"æ‰¾åˆ° {len(failed_queues)} ä¸ªçŠ¶æ€ä¸º failed çš„æŠ½å–é˜Ÿåˆ—é¡¹:")
        print("\n" + "=" * 80)
        for i, queue in enumerate(failed_queues, 1):
            article = queue.article
            print(f"{i}. [Queue ID:{queue.id}] [Article ID:{queue.article_id}]")
            print(f"   æ ‡é¢˜: {article.title[:60]}")
            print(f"   URL: {article.url[:80]}")
            print(f"   å‘å¸ƒæ—¶é—´: {article.published_at}")
            print(f"   é‡‡é›†æ—¶é—´: {article.fetched_at}")
            print(f"   é˜Ÿåˆ—çŠ¶æ€: {queue.status}")
            print(f"   å°è¯•æ¬¡æ•°: {queue.attempts}")
            if queue.last_error:
                print(f"   æœ€åé”™è¯¯: {queue.last_error[:100]}...")
        print("=" * 80 + "\n")

        if dry_run:
            logger.info("ğŸ” é¢„è§ˆæ¨¡å¼: ä¸æ‰§è¡Œä¿®æ”¹æ“ä½œ")
            logger.info(f"å¦‚éœ€ä¿®æ”¹,è¯·å»æ‰ --dry-run å‚æ•°é‡æ–°æ‰§è¡Œ")
            return

        # ç¡®è®¤ä¿®æ”¹
        logger.warning(f"å³å°†ä¿®æ”¹ {len(failed_queues)} ä¸ªé˜Ÿåˆ—é¡¹çš„çŠ¶æ€: failed -> queued")

        # æ‰§è¡Œä¿®æ”¹
        for queue in failed_queues:
            queue.status = QueueStatus.QUEUED
            # å¯é€‰: é‡ç½®å°è¯•æ¬¡æ•°å’Œé”™è¯¯ä¿¡æ¯
            # queue.attempts = 0
            # queue.last_error = None
            # queue.processing_started_at = None
            # queue.processing_finished_at = None

        session.commit()

        logger.success(f"âœ… æˆåŠŸä¿®æ”¹ {len(failed_queues)} ä¸ªé˜Ÿåˆ—é¡¹çš„çŠ¶æ€ä¸º queued (å¾…å¤„ç†)")
        logger.info(f"æ¥ä¸‹æ¥å¯ä»¥è¿è¡Œ: python -m src.cli.run_once --step extract --date {date_str}")

    except Exception as e:
        session.rollback()
        logger.error(f"âŒ æ“ä½œå¤±è´¥: {e}", exc_info=True)
        raise
    finally:
        session.close()


def main():
    parser = argparse.ArgumentParser(description="é‡ç½®å¤±è´¥çš„æŠ½å–é˜Ÿåˆ—çŠ¶æ€")
    parser.add_argument(
        "--date",
        type=str,
        required=True,
        help="æŒ‡å®šæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD, ä¾‹å¦‚: 2025-11-30)"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="é¢„è§ˆæ¨¡å¼,åªæŸ¥çœ‹ä¸ä¿®æ”¹"
    )

    args = parser.parse_args()

    # éªŒè¯æ—¥æœŸæ ¼å¼
    try:
        datetime.strptime(args.date, "%Y-%m-%d")
    except ValueError:
        logger.error("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯,è¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼ (ä¾‹å¦‚: 2025-11-30)")
        return

    reset_failed_queue(args.date, args.dry_run)


if __name__ == "__main__":
    main()
